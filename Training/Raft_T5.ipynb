{"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9653302,"sourceType":"datasetVersion","datasetId":5896638},{"sourceId":9656264,"sourceType":"datasetVersion","datasetId":5898853},{"sourceId":10260,"sourceType":"modelInstanceVersion","modelInstanceId":5171,"modelId":3533},{"sourceId":139017,"sourceType":"modelInstanceVersion","modelInstanceId":117718,"modelId":140952},{"sourceId":144224,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":122235,"modelId":145327}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"papermill":{"default_parameters":{},"duration":897.635437,"end_time":"2024-02-21T09:52:28.59121","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-02-21T09:37:30.955773","version":"2.5.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Setting up the environment","metadata":{}},{"cell_type":"code","source":"# Install Keras 3 last. See https://keras.io/getting_started/ for more details.\n!pip install -q -U keras-nlp\n!pip install -q -U keras>=3","metadata":{"id":"1eeBtYqJsZPG","outputId":"d0645149-4fe7-4304-81dd-cb18354cd7c9","papermill":{"duration":29.215629,"end_time":"2024-02-21T09:38:03.131031","exception":false,"start_time":"2024-02-21T09:37:33.915402","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-23T11:04:21.878016Z","iopub.execute_input":"2024-10-23T11:04:21.878335Z","iopub.status.idle":"2024-10-23T11:04:49.611929Z","shell.execute_reply.started":"2024-10-23T11:04:21.878303Z","shell.execute_reply":"2024-10-23T11:04:49.610689Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\n\nos.environ[\"KERAS_BACKEND\"] = \"jax\"  # Or \"torch\" or \"tensorflow\".\n# Avoid memory fragmentation on JAX backend.\nos.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\"1.00\"","metadata":{"id":"yn5uy8X8sdD0","papermill":{"duration":0.017153,"end_time":"2024-02-21T09:38:03.175604","exception":false,"start_time":"2024-02-21T09:38:03.158451","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-23T11:04:49.614117Z","iopub.execute_input":"2024-10-23T11:04:49.614487Z","iopub.status.idle":"2024-10-23T11:04:49.620250Z","shell.execute_reply.started":"2024-10-23T11:04:49.614452Z","shell.execute_reply":"2024-10-23T11:04:49.619208Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import keras\nimport keras_nlp","metadata":{"id":"FYHyPUA9hKTf","papermill":{"duration":13.723138,"end_time":"2024-02-21T09:38:16.925885","exception":false,"start_time":"2024-02-21T09:38:03.202747","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-23T11:04:49.621225Z","iopub.execute_input":"2024-10-23T11:04:49.621479Z","iopub.status.idle":"2024-10-23T11:05:01.787002Z","shell.execute_reply.started":"2024-10-23T11:04:49.621450Z","shell.execute_reply":"2024-10-23T11:05:01.786254Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Load Dataset","metadata":{"id":"9T7xe_jzslv4","papermill":{"duration":0.008653,"end_time":"2024-02-21T09:38:16.943901","exception":false,"start_time":"2024-02-21T09:38:16.935248","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import pandas as pd\nnew_data = pd.read_json('/kaggle/input/nlp-197/nlp-197.json')\nnew_data","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:05:01.787996Z","iopub.execute_input":"2024-10-23T11:05:01.788610Z","iopub.status.idle":"2024-10-23T11:05:01.973843Z","shell.execute_reply.started":"2024-10-23T11:05:01.788574Z","shell.execute_reply":"2024-10-23T11:05:01.972969Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                id     type  \\\n0      seed_task_0  general   \n1      seed_task_1  general   \n2      seed_task_2  general   \n3      seed_task_3  general   \n4      seed_task_4  general   \n..             ...      ...   \n875  seed_task_875  general   \n876  seed_task_876  general   \n877  seed_task_877  general   \n878  seed_task_878  general   \n879  seed_task_879  general   \n\n                                              question  \\\n0                                   What is Spark NLP?   \n1             What are the main features of Spark NLP?   \n2       What is the impact of Spark NLP on healthcare?   \n3    What are the main challenges associated with S...   \n4          What are the future prospects of Spark NLP?   \n..                                                 ...   \n875  What is the most frequent language generation ...   \n876  What are the two main types of summaries discu...   \n877  What is the Financial Narrative Summarization ...   \n878       What was the focus of the FNS-2023 workshop?   \n879  What is the predominant summarization techniqu...   \n\n                                               context  \\\n0    {'sentences': [['Learning with pseudo-ensemble...   \n1    {'sentences': [['vectors while the right side ...   \n2    {'sentences': [['a sentence, the juxtaposition...   \n3    {'sentences': [['P(w i|cj)=P(cj|wi)P(wi)/summa...   \n4    {'sentences': [['whose performance has been co...   \n..                                                 ...   \n875  {'sentences': [['Generation Rules Generation r...   \n876  {'sentences': [['queries on knowledge graphs. ...   \n877  {'sentences': [['the feasibility and signiﬁcan...   \n878  {'sentences': [['34, pages 13001–13008. Chen Z...   \n879  {'sentences': [['Martti Tapani Vainio, et al. ...   \n\n                                                answer  cot_answer  \n0    Spark NLP is a Natural Language Processing (NL...         NaN  \n1    Spark NLP comes with 1100+ pretrained pipeline...         NaN  \n2    Spark NLP is used by 54% of healthcare organiz...         NaN  \n3    There are no challenges associated with Spark ...         NaN  \n4    The text does not provide information about th...         NaN  \n..                                                 ...         ...  \n875     Sequence-to-sequence Transformer architectures         NaN  \n876               Extractive and abstractive summaries         NaN  \n877  A shared task series for generating summaries ...         NaN  \n878  Generating either extractive or abstractive su...         NaN  \n879                           Extractive summarization         NaN  \n\n[880 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>type</th>\n      <th>question</th>\n      <th>context</th>\n      <th>answer</th>\n      <th>cot_answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>seed_task_0</td>\n      <td>general</td>\n      <td>What is Spark NLP?</td>\n      <td>{'sentences': [['Learning with pseudo-ensemble...</td>\n      <td>Spark NLP is a Natural Language Processing (NL...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>seed_task_1</td>\n      <td>general</td>\n      <td>What are the main features of Spark NLP?</td>\n      <td>{'sentences': [['vectors while the right side ...</td>\n      <td>Spark NLP comes with 1100+ pretrained pipeline...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>seed_task_2</td>\n      <td>general</td>\n      <td>What is the impact of Spark NLP on healthcare?</td>\n      <td>{'sentences': [['a sentence, the juxtaposition...</td>\n      <td>Spark NLP is used by 54% of healthcare organiz...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>seed_task_3</td>\n      <td>general</td>\n      <td>What are the main challenges associated with S...</td>\n      <td>{'sentences': [['P(w i|cj)=P(cj|wi)P(wi)/summa...</td>\n      <td>There are no challenges associated with Spark ...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>seed_task_4</td>\n      <td>general</td>\n      <td>What are the future prospects of Spark NLP?</td>\n      <td>{'sentences': [['whose performance has been co...</td>\n      <td>The text does not provide information about th...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>875</th>\n      <td>seed_task_875</td>\n      <td>general</td>\n      <td>What is the most frequent language generation ...</td>\n      <td>{'sentences': [['Generation Rules Generation r...</td>\n      <td>Sequence-to-sequence Transformer architectures</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>876</th>\n      <td>seed_task_876</td>\n      <td>general</td>\n      <td>What are the two main types of summaries discu...</td>\n      <td>{'sentences': [['queries on knowledge graphs. ...</td>\n      <td>Extractive and abstractive summaries</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>877</th>\n      <td>seed_task_877</td>\n      <td>general</td>\n      <td>What is the Financial Narrative Summarization ...</td>\n      <td>{'sentences': [['the feasibility and signiﬁcan...</td>\n      <td>A shared task series for generating summaries ...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>878</th>\n      <td>seed_task_878</td>\n      <td>general</td>\n      <td>What was the focus of the FNS-2023 workshop?</td>\n      <td>{'sentences': [['34, pages 13001–13008. Chen Z...</td>\n      <td>Generating either extractive or abstractive su...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>879</th>\n      <td>seed_task_879</td>\n      <td>general</td>\n      <td>What is the predominant summarization techniqu...</td>\n      <td>{'sentences': [['Martti Tapani Vainio, et al. ...</td>\n      <td>Extractive summarization</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>880 rows × 6 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"new_data['question'][0]","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:05:01.976329Z","iopub.execute_input":"2024-10-23T11:05:01.976653Z","iopub.status.idle":"2024-10-23T11:05:01.982784Z","shell.execute_reply.started":"2024-10-23T11:05:01.976620Z","shell.execute_reply":"2024-10-23T11:05:01.981740Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"'What is Spark NLP?'"},"metadata":{}}]},{"cell_type":"code","source":"sentence = str(new_data['context'].iloc[0])\nsentence = sentence.replace(\"{\", \"\", 1)  # Removes only the first occurrence","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:05:01.984036Z","iopub.execute_input":"2024-10-23T11:05:01.984434Z","iopub.status.idle":"2024-10-23T11:05:01.991417Z","shell.execute_reply.started":"2024-10-23T11:05:01.984389Z","shell.execute_reply":"2024-10-23T11:05:01.990519Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"for i, sentence in enumerate(new_data['context']):\n    sentence = str(new_data['context'].iloc[i])\n    sentence = sentence.replace(\"{\", \"\").replace(\"}\", \"\")\n    new_data.at[i, 'context'] = sentence","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:05:01.992616Z","iopub.execute_input":"2024-10-23T11:05:01.992989Z","iopub.status.idle":"2024-10-23T11:05:02.093850Z","shell.execute_reply.started":"2024-10-23T11:05:01.992945Z","shell.execute_reply":"2024-10-23T11:05:02.093140Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"new_data","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:05:02.094797Z","iopub.execute_input":"2024-10-23T11:05:02.095070Z","iopub.status.idle":"2024-10-23T11:05:02.108146Z","shell.execute_reply.started":"2024-10-23T11:05:02.095040Z","shell.execute_reply":"2024-10-23T11:05:02.107226Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                id     type  \\\n0      seed_task_0  general   \n1      seed_task_1  general   \n2      seed_task_2  general   \n3      seed_task_3  general   \n4      seed_task_4  general   \n..             ...      ...   \n875  seed_task_875  general   \n876  seed_task_876  general   \n877  seed_task_877  general   \n878  seed_task_878  general   \n879  seed_task_879  general   \n\n                                              question  \\\n0                                   What is Spark NLP?   \n1             What are the main features of Spark NLP?   \n2       What is the impact of Spark NLP on healthcare?   \n3    What are the main challenges associated with S...   \n4          What are the future prospects of Spark NLP?   \n..                                                 ...   \n875  What is the most frequent language generation ...   \n876  What are the two main types of summaries discu...   \n877  What is the Financial Narrative Summarization ...   \n878       What was the focus of the FNS-2023 workshop?   \n879  What is the predominant summarization techniqu...   \n\n                                               context  \\\n0    'sentences': [['Learning with pseudo-ensembles...   \n1    'sentences': [['vectors while the right side o...   \n2    'sentences': [['a sentence, the juxtaposition ...   \n3    'sentences': [['P(w i|cj)=P(cj|wi)P(wi)/summat...   \n4    'sentences': [['whose performance has been con...   \n..                                                 ...   \n875  'sentences': [['Generation Rules Generation ru...   \n876  'sentences': [['queries on knowledge graphs. I...   \n877  'sentences': [['the feasibility and signiﬁcant...   \n878  'sentences': [['34, pages 13001–13008. Chen Zh...   \n879  'sentences': [['Martti Tapani Vainio, et al. 2...   \n\n                                                answer  cot_answer  \n0    Spark NLP is a Natural Language Processing (NL...         NaN  \n1    Spark NLP comes with 1100+ pretrained pipeline...         NaN  \n2    Spark NLP is used by 54% of healthcare organiz...         NaN  \n3    There are no challenges associated with Spark ...         NaN  \n4    The text does not provide information about th...         NaN  \n..                                                 ...         ...  \n875     Sequence-to-sequence Transformer architectures         NaN  \n876               Extractive and abstractive summaries         NaN  \n877  A shared task series for generating summaries ...         NaN  \n878  Generating either extractive or abstractive su...         NaN  \n879                           Extractive summarization         NaN  \n\n[880 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>type</th>\n      <th>question</th>\n      <th>context</th>\n      <th>answer</th>\n      <th>cot_answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>seed_task_0</td>\n      <td>general</td>\n      <td>What is Spark NLP?</td>\n      <td>'sentences': [['Learning with pseudo-ensembles...</td>\n      <td>Spark NLP is a Natural Language Processing (NL...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>seed_task_1</td>\n      <td>general</td>\n      <td>What are the main features of Spark NLP?</td>\n      <td>'sentences': [['vectors while the right side o...</td>\n      <td>Spark NLP comes with 1100+ pretrained pipeline...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>seed_task_2</td>\n      <td>general</td>\n      <td>What is the impact of Spark NLP on healthcare?</td>\n      <td>'sentences': [['a sentence, the juxtaposition ...</td>\n      <td>Spark NLP is used by 54% of healthcare organiz...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>seed_task_3</td>\n      <td>general</td>\n      <td>What are the main challenges associated with S...</td>\n      <td>'sentences': [['P(w i|cj)=P(cj|wi)P(wi)/summat...</td>\n      <td>There are no challenges associated with Spark ...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>seed_task_4</td>\n      <td>general</td>\n      <td>What are the future prospects of Spark NLP?</td>\n      <td>'sentences': [['whose performance has been con...</td>\n      <td>The text does not provide information about th...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>875</th>\n      <td>seed_task_875</td>\n      <td>general</td>\n      <td>What is the most frequent language generation ...</td>\n      <td>'sentences': [['Generation Rules Generation ru...</td>\n      <td>Sequence-to-sequence Transformer architectures</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>876</th>\n      <td>seed_task_876</td>\n      <td>general</td>\n      <td>What are the two main types of summaries discu...</td>\n      <td>'sentences': [['queries on knowledge graphs. I...</td>\n      <td>Extractive and abstractive summaries</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>877</th>\n      <td>seed_task_877</td>\n      <td>general</td>\n      <td>What is the Financial Narrative Summarization ...</td>\n      <td>'sentences': [['the feasibility and signiﬁcant...</td>\n      <td>A shared task series for generating summaries ...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>878</th>\n      <td>seed_task_878</td>\n      <td>general</td>\n      <td>What was the focus of the FNS-2023 workshop?</td>\n      <td>'sentences': [['34, pages 13001–13008. Chen Zh...</td>\n      <td>Generating either extractive or abstractive su...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>879</th>\n      <td>seed_task_879</td>\n      <td>general</td>\n      <td>What is the predominant summarization techniqu...</td>\n      <td>'sentences': [['Martti Tapani Vainio, et al. 2...</td>\n      <td>Extractive summarization</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>880 rows × 6 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Train Test Split","metadata":{}},{"cell_type":"code","source":"train_data = new_data[:440]\ntest_data = new_data[440:]\n\ntest_data","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:05:02.109353Z","iopub.execute_input":"2024-10-23T11:05:02.109676Z","iopub.status.idle":"2024-10-23T11:05:02.125179Z","shell.execute_reply.started":"2024-10-23T11:05:02.109642Z","shell.execute_reply":"2024-10-23T11:05:02.124232Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                id     type  \\\n440  seed_task_440  general   \n441  seed_task_441  general   \n442  seed_task_442  general   \n443  seed_task_443  general   \n444  seed_task_444  general   \n..             ...      ...   \n875  seed_task_875  general   \n876  seed_task_876  general   \n877  seed_task_877  general   \n878  seed_task_878  general   \n879  seed_task_879  general   \n\n                                              question  \\\n440                What is the main topic of the text?   \n441  What is the purpose of the quality assurance c...   \n442     How many bibliographic records were retrieved?   \n443          What metadata is included in each record?   \n444     What is the purpose of the filtering strategy?   \n..                                                 ...   \n875  What is the most frequent language generation ...   \n876  What are the two main types of summaries discu...   \n877  What is the Financial Narrative Summarization ...   \n878       What was the focus of the FNS-2023 workshop?   \n879  What is the predominant summarization techniqu...   \n\n                                               context  \\\n440  'sentences': [['x ∈ K , suppose TKA(x)◦∩range(...   \n441  'sentences': [['to better grasp both evidence ...   \n442  'sentences': [['a polynomial proximity matrix ...   \n443  'sentences': [['holds clear promise for energe...   \n444  'sentences': [['2020. Dynamic memory induction...   \n..                                                 ...   \n875  'sentences': [['Generation Rules Generation ru...   \n876  'sentences': [['queries on knowledge graphs. I...   \n877  'sentences': [['the feasibility and signiﬁcant...   \n878  'sentences': [['34, pages 13001–13008. Chen Zh...   \n879  'sentences': [['Martti Tapani Vainio, et al. 2...   \n\n                                                answer  cot_answer  \n440  The text does not explicitly state a main topi...         NaN  \n441  The purpose of the quality assurance check is ...         NaN  \n442  A total of 1,717 bibliographic records were re...         NaN  \n443  Each record includes metadata such as the titl...         NaN  \n444  The filtering strategy is used to reduce the n...         NaN  \n..                                                 ...         ...  \n875     Sequence-to-sequence Transformer architectures         NaN  \n876               Extractive and abstractive summaries         NaN  \n877  A shared task series for generating summaries ...         NaN  \n878  Generating either extractive or abstractive su...         NaN  \n879                           Extractive summarization         NaN  \n\n[440 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>type</th>\n      <th>question</th>\n      <th>context</th>\n      <th>answer</th>\n      <th>cot_answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>440</th>\n      <td>seed_task_440</td>\n      <td>general</td>\n      <td>What is the main topic of the text?</td>\n      <td>'sentences': [['x ∈ K , suppose TKA(x)◦∩range(...</td>\n      <td>The text does not explicitly state a main topi...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>441</th>\n      <td>seed_task_441</td>\n      <td>general</td>\n      <td>What is the purpose of the quality assurance c...</td>\n      <td>'sentences': [['to better grasp both evidence ...</td>\n      <td>The purpose of the quality assurance check is ...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>442</th>\n      <td>seed_task_442</td>\n      <td>general</td>\n      <td>How many bibliographic records were retrieved?</td>\n      <td>'sentences': [['a polynomial proximity matrix ...</td>\n      <td>A total of 1,717 bibliographic records were re...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>443</th>\n      <td>seed_task_443</td>\n      <td>general</td>\n      <td>What metadata is included in each record?</td>\n      <td>'sentences': [['holds clear promise for energe...</td>\n      <td>Each record includes metadata such as the titl...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>444</th>\n      <td>seed_task_444</td>\n      <td>general</td>\n      <td>What is the purpose of the filtering strategy?</td>\n      <td>'sentences': [['2020. Dynamic memory induction...</td>\n      <td>The filtering strategy is used to reduce the n...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>875</th>\n      <td>seed_task_875</td>\n      <td>general</td>\n      <td>What is the most frequent language generation ...</td>\n      <td>'sentences': [['Generation Rules Generation ru...</td>\n      <td>Sequence-to-sequence Transformer architectures</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>876</th>\n      <td>seed_task_876</td>\n      <td>general</td>\n      <td>What are the two main types of summaries discu...</td>\n      <td>'sentences': [['queries on knowledge graphs. I...</td>\n      <td>Extractive and abstractive summaries</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>877</th>\n      <td>seed_task_877</td>\n      <td>general</td>\n      <td>What is the Financial Narrative Summarization ...</td>\n      <td>'sentences': [['the feasibility and signiﬁcant...</td>\n      <td>A shared task series for generating summaries ...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>878</th>\n      <td>seed_task_878</td>\n      <td>general</td>\n      <td>What was the focus of the FNS-2023 workshop?</td>\n      <td>'sentences': [['34, pages 13001–13008. Chen Zh...</td>\n      <td>Generating either extractive or abstractive su...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>879</th>\n      <td>seed_task_879</td>\n      <td>general</td>\n      <td>What is the predominant summarization techniqu...</td>\n      <td>'sentences': [['Martti Tapani Vainio, et al. 2...</td>\n      <td>Extractive summarization</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>440 rows × 6 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Creating inference Data","metadata":{}},{"cell_type":"code","source":"!pip install -qU langchain-openai","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:05:02.126314Z","iopub.execute_input":"2024-10-23T11:05:02.126635Z","iopub.status.idle":"2024-10-23T11:05:16.366038Z","shell.execute_reply.started":"2024-10-23T11:05:02.126604Z","shell.execute_reply":"2024-10-23T11:05:16.365089Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 24.8.3 requires cubinlinker, which is not installed.\ncudf 24.8.3 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.8.3 requires ptxcompiler, which is not installed.\ncuml 24.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 24.8.3 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.8.3 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.0 which is incompatible.\ndistributed 2024.7.1 requires dask==2024.7.1, but you have dask 2024.9.1 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.1 which is incompatible.\njupyterlab 4.2.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.5.0 requires requests-toolbelt<1,>=0.8.0, but you have requests-toolbelt 1.0.0 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nrapids-dask-dependency 24.8.0a0 requires dask==2024.7.1, but you have dask 2024.9.1 which is incompatible.\nydata-profiling 4.10.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"%pip install --quiet --upgrade langchain langchain-community langchain-chroma","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:05:16.367424Z","iopub.execute_input":"2024-10-23T11:05:16.367729Z","iopub.status.idle":"2024-10-23T11:05:54.466686Z","shell.execute_reply.started":"2024-10-23T11:05:16.367696Z","shell.execute_reply":"2024-10-23T11:05:54.465644Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.5.0 requires kubernetes<27,>=8.0.0, but you have kubernetes 31.0.0 which is incompatible.\nkfp 2.5.0 requires requests-toolbelt<1,>=0.8.0, but you have requests-toolbelt 1.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import bs4\nfrom langchain import hub\nfrom langchain_chroma import Chroma\nfrom langchain_community.document_loaders import WebBaseLoader\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.runnables import RunnablePassthrough\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:05:54.469028Z","iopub.execute_input":"2024-10-23T11:05:54.469685Z","iopub.status.idle":"2024-10-23T11:05:56.969844Z","shell.execute_reply.started":"2024-10-23T11:05:54.469636Z","shell.execute_reply":"2024-10-23T11:05:56.968778Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import json\nfile_path = '/kaggle/input/nlp-chunks/chunks.json'\nwith open(file_path, 'r') as f:\n    chunks = json.load(f)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:05:56.971115Z","iopub.execute_input":"2024-10-23T11:05:56.971761Z","iopub.status.idle":"2024-10-23T11:05:57.049518Z","shell.execute_reply.started":"2024-10-23T11:05:56.971723Z","shell.execute_reply":"2024-10-23T11:05:57.048729Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"print(len(chunks))","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:05:57.052882Z","iopub.execute_input":"2024-10-23T11:05:57.053162Z","iopub.status.idle":"2024-10-23T11:05:57.057872Z","shell.execute_reply.started":"2024-10-23T11:05:57.053130Z","shell.execute_reply":"2024-10-23T11:05:57.056972Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"3926\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install einops","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:05:57.059083Z","iopub.execute_input":"2024-10-23T11:05:57.059431Z","iopub.status.idle":"2024-10-23T11:06:08.937288Z","shell.execute_reply.started":"2024-10-23T11:05:57.059398Z","shell.execute_reply":"2024-10-23T11:06:08.936265Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Collecting einops\n  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\nDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: einops\nSuccessfully installed einops-0.8.0\n","output_type":"stream"}]},{"cell_type":"code","source":"print(chunks[0])","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:06:08.938837Z","iopub.execute_input":"2024-10-23T11:06:08.939189Z","iopub.status.idle":"2024-10-23T11:06:08.946205Z","shell.execute_reply.started":"2024-10-23T11:06:08.939152Z","shell.execute_reply":"2024-10-23T11:06:08.945157Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Spark NLP: Natural Language Understanding at Scale Veysel Kocaman, David Talby John Snow Labs Inc. 16192 Coastal Highway Lewes, DE , USA 19958 veysel, david@johnsnowlabs.com Abstract Spark NLP is a Natural Language Processing (NLP) library built on top of Apache Spark ML. It provides simple, performant & accurate NLP annotations for machine learning pipelines that can scale easily in a distributed environment. Spark NLP comes with 1100+ pretrained pipelines and models in more than 192+ languages. It supports nearly all the NLP tasks and modules that can be used seam- lessly in a cluster. Downloaded more than 2.7 million times and experiencing 9x growth since January 2020, Spark NLP is used by 54% of healthcare organizations as the world’s most widely used NLP library in the enterprise. Keywords: spark, natural language processing, deep learning, tensorﬂow, cluster 1. Spark NLP Library Natural language processing (NLP) is a key component in many data \n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -U sentence-transformers\nfrom sentence_transformers import SentenceTransformer, util\nmodel = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')\n\nquery_embedding = model.encode('How big is London')\npassage_embedding = model.encode(['London has 9,787,426 inhabitants at the 2011 census',\n                                  'London is known for its finacial district'])\n\nprint(\"Similarity:\", util.dot_score(query_embedding, passage_embedding))","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:06:08.947475Z","iopub.execute_input":"2024-10-23T11:06:08.947799Z","iopub.status.idle":"2024-10-23T11:06:30.349275Z","shell.execute_reply.started":"2024-10-23T11:06:08.947767Z","shell.execute_reply":"2024-10-23T11:06:30.348338Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Collecting sentence-transformers\n  Downloading sentence_transformers-3.2.1-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.45.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.4)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.4.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.14.1)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.25.1)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (10.3.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.5.15)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.0)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\nDownloading sentence_transformers-3.2.1-py3-none-any.whl (255 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.8/255.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-3.2.1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17987b044f5841f69c78d928382069f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb5ceaa0b70e4eb08b3db21bcc73b251"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/11.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b283b5147fc24d2fadb64e87273df519"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f41559b7f2a245cdbe5b70427a686485"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81340eb17fd049e0986933489504dfce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30b479adc94b41488bc4d3c5d6d89331"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/383 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4d09c5720554e07938c37fb3f9c44b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84b14824db25446b9ef7a7e7d5ac151b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d37fac1983c148f9ac9a33a7c0cbd2bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42b9bf5dfc4846b3bfbe77182258b82c"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3635a23f7e34776840b61a2a635cf9c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4187b186f97a4d46b6e970d091f86348"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"225fa63292454f5f977186601a58e81a"}},"metadata":{}},{"name":"stdout","text":"Similarity: tensor([[0.5472, 0.6330]])\n","output_type":"stream"}]},{"cell_type":"code","source":"passage_embedding = model.encode(chunks)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:06:30.350619Z","iopub.execute_input":"2024-10-23T11:06:30.351769Z","iopub.status.idle":"2024-10-23T11:06:41.435374Z","shell.execute_reply.started":"2024-10-23T11:06:30.351718Z","shell.execute_reply":"2024-10-23T11:06:41.434593Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/123 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0fb16747075448aa946df823736b468"}},"metadata":{}}]},{"cell_type":"code","source":"import torch\nquery_embedding = model.encode('What is spark NLP')\nscores = util.dot_score(query_embedding, passage_embedding)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:06:41.436518Z","iopub.execute_input":"2024-10-23T11:06:41.436826Z","iopub.status.idle":"2024-10-23T11:06:41.478362Z","shell.execute_reply.started":"2024-10-23T11:06:41.436794Z","shell.execute_reply":"2024-10-23T11:06:41.477372Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dabfa0ea59fe422ab084d946792e9c2c"}},"metadata":{}}]},{"cell_type":"code","source":"values, indices = torch.topk(scores, 5)\nprint(values)\nprint(len(indices[0]))","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:06:41.479567Z","iopub.execute_input":"2024-10-23T11:06:41.479885Z","iopub.status.idle":"2024-10-23T11:06:41.490865Z","shell.execute_reply.started":"2024-10-23T11:06:41.479850Z","shell.execute_reply":"2024-10-23T11:06:41.489893Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"tensor([[0.7582, 0.7382, 0.7009, 0.6594, 0.6387]])\n5\n","output_type":"stream"}]},{"cell_type":"code","source":"chunks[int(indices[0][4])]","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:06:41.491889Z","iopub.execute_input":"2024-10-23T11:06:41.492202Z","iopub.status.idle":"2024-10-23T11:06:41.499346Z","shell.execute_reply.started":"2024-10-23T11:06:41.492155Z","shell.execute_reply":"2024-10-23T11:06:41.498366Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"'driver node. There is a CuDA version of each TensorFlow component to enable training models on GPU when available. The Spark NLP is written in Scala and provides open-source API’s in Python, Java, Scala, and R - so that users do not need to be aware of the underlying implementation details (TensorFlow, Spark, etc.) in order to use it. Since it has an active release cycle (released 26 new versions in 2019 and another 26 in 2020), the latest trends and research in NLP ﬁeld are embraced and implemented rapidly in a way that could scale well in a cluster setting to allow common NLP pipelines run orders of magnitude faster than what the inherent design limitations of legacy libraries allowed. Spark NLP library has two versions: Open source and enterprise. Open source version has all the features and components that could be expected from any NLP library, using the '"},"metadata":{}}]},{"cell_type":"code","source":"#In a for loop. Generate the top 5 contexts for each question and append it to the question as the prompt\n#Then get the answer and do inference","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:06:41.500632Z","iopub.execute_input":"2024-10-23T11:06:41.500998Z","iopub.status.idle":"2024-10-23T11:06:41.507831Z","shell.execute_reply.started":"2024-10-23T11:06:41.500956Z","shell.execute_reply":"2024-10-23T11:06:41.506934Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"test_data['question'].iloc[0]","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:06:41.508842Z","iopub.execute_input":"2024-10-23T11:06:41.509141Z","iopub.status.idle":"2024-10-23T11:06:41.519799Z","shell.execute_reply.started":"2024-10-23T11:06:41.509107Z","shell.execute_reply":"2024-10-23T11:06:41.518900Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"'What is the main topic of the text?'"},"metadata":{}}]},{"cell_type":"code","source":"inference_data = []\nfor i in range(0, test_data.shape[0]):\n    question  = test_data['question'].iloc[i]\n    \n    query_embedding = model.encode(question)\n    scores = util.dot_score(query_embedding, passage_embedding)\n    values, indices = torch.topk(scores, 5)\n    context = \"\"\n    for j in range(len(indices[0])):\n        context = context + \"\\n\" + chunks[int(indices[0][j])]\n        \n    answer = test_data['answer'].iloc[i]\n    template = f\"Instruction:\\n{question}\\n\\nContext:\\n{context}\"\n    inference_data.append(template)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:06:41.520818Z","iopub.execute_input":"2024-10-23T11:06:41.521118Z","iopub.status.idle":"2024-10-23T11:06:52.503051Z","shell.execute_reply.started":"2024-10-23T11:06:41.521085Z","shell.execute_reply":"2024-10-23T11:06:52.502123Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7362914aa2744e33858583b983439cc4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ddb1c85bfba2430fb9c4c7103cee8229"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e557fd931fb24407b2932acd4ab13f92"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a424d2a1196c4c2d94957eb196d905d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfd6bba834714f4ea24cd86a8ebcbe28"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0efc8dc750e4a36828d0369e7ead4f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9888c3a61f244eb48431be2182f18be3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7641a0a6955a4412aabed665fc2841a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f09c669093274d5795c47327c920d59c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6be52720d9a42b0be41d0ec628de779"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fcf44aa557914ec38b5d3e7f1a66b3c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1601de3dd4024ed2b09415445454493f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f423816073e482694202ebfee22817f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b45319253ca4bcd82819b512b10eeb8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b05a266fe964109a735622472b6f688"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b05494b15e454ffcab8125df9ca60b4b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"221d5dd7711342859587112daf2b2144"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49fd8c17f98e44888fd3c1bdfb2dc5c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"960a00be9bf9452997c0ed691b285371"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b667d4a7acb4930b22afdd9b3996f46"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6e377e281c142198e69aab1a56d467b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"539e6fbe86fa46eb890cf6962f60ffa8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39de1790608647c698df1c61e355d083"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e701ff6378cf42279e052b11af6687bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1c6c3ce9fa94120b4e3052aa30a1fdd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9fc767d59b64035a7531de3e67092b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22347b8bf2aa4764a58264d6c2f9217e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9dbaddb6bc044ab789c9ed00cf1b97be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba73a0c31d1945b4a5c63bbd09fabd1a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07f0cfce4f6e43a98a690a8c27bfdd93"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1db698e08ec5419a9c93a637ee4d71ec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a4fc28f09084c7aa916aa821926fdb8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df1dfef4c2db4273b5ab74ca82150299"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"015552f3fc9d427abc68e8c6599376d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e0977c5b94e4d3fa71a81260731dd28"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1eb204fa39ce473cb814e7cb9a9bcc6c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0d5c02dbf5b42499222a116b9d60946"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e53c75df7e904f0b96a7573282592221"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ea76be48e904802b7313ab05f7efd1b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5469336f6d1d40e68073f22663c1c012"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"743a8ddb532745eea4427fd5fda46c58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1879a8e552e84243855cbb927d30cd51"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbe3c557ca6c4e41a46e9f2a52f29726"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f368fea7a68b464cab5d6c6cb6323fda"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e93c848408bb46cda12ab8890c1603b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"203618727dba44d6840b8d8fdb73e734"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"334e88cc8a9a47708fd6c26e133aaadb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58edcbdfba874ce79a9c5e3adb9ae2e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c98a997ee9641e5886639e8ac85203b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ca419ca74554cd985d1e9c73abe218b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"826d44ceb29c44429a6e5f0f60d5d8c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7579b3b31bc24561bc60d27fb82fa51f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a925c82e7c284f4fa48a7d2312e5ec07"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0375e7c31f3b41718b3e63d10ea25d7d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"813414add56c46e59f6dcbb495052545"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8945831cd3647409ddc9c0fda8dccc9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"334e3d683fd84efb9e21beba9004a611"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"357caa8ce0254076999ac62bce95951a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f26b2ea08d524c1096eec2d56533f21d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8dd7c92427fa4f088de669bcbc7aa08c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e7ae7362fc34f0c937bb54fd7e51522"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"694ea24b3be84383a57b0cf1720bb298"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e18c8d676dac4f218c09384116eb4709"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"264c1dda3bd34435b5bb59cc371a6009"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4edb49cb8d5491aa34cc3273655d87c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d989b201dbfe4e36883477c32eb30964"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abe23bcac6ef4dedbc166551edac33bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b83cfd59946e4e7da4ad528f845ab95b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"450bdbca8deb42b78c8ea2834c8ae9f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2df6582398784d40a11caa70d540c19f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25eb08de81254d98a3af401cfece7e9f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"933a4cd83c914951897da9e2c08ce6a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14c221f0653b4a778a9267013c6195ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"205e56a4f5f94a3b90db1e9cb716bb60"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd284e4c54994b7ab659d3043c9dc230"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2005f30519d4525abba855cf123a5c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ce88700cba04e4ea8390331fd53f020"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"472de6de05094bf3acdd7acb4aa4350a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9b41bc5caac4214b88103d81a5f94f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46ad4bd85d9642b495c20f879df9be78"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2dc92a72e1b4781a3644a2117e3011a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7bb6961a8c2b40eeabdccafd299e9f7d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99a3e19ddf1b4ed2b07bc82d2ededb69"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6fd38adfedc4eeeb98c5a972a0956df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79c609649fcd446d8322bbac8b13c7c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dcd156a9219645fea66bde0032d674cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f1f7e0b6a2645b5bf8b77cd0fbf5385"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2722ed4c0f1b4c8bbc88111eb8b9beee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48a9c72efd4749cba1cc313162f643a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8a5c874436647e093e9455c3d89e05b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d942fc6944a7441bb8ee26955a038f82"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29c59d4879a8456c99a7cc59d708e241"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04589dfc762349d6b1d65f5c2d061337"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80f9a53687b34517887bdc0d74f298ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efaafd0256a44708a531d2acc926e3a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2d280b5a82647429d0c3cc500ebdb56"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c9b3e1c3fa24a71af45d60b787340a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08ccfb6aa763447da10262b090b2d651"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1976cd95da104f538aad2c864d298cac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a28eaeddaaee442aa14590cf5391bdec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbc82fef737f43a081cb569a752d14f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"645f464be4eb47bc9b951138fcca3395"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd1322b5446445478ddbed1e55f6c540"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69338ad77555430bab73bde69a613581"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4add4809d0e045d084e2cbf7d6f9200b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"911343f023dc44828fd26665a61403d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99af817f8da34cd1af021b528eef7a25"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8052bac1fa524f24bb741cf3a9209d98"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"877900179f6a4142bc8013389fb9619d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4e628e5e3f84b6f8f3feb4188d3939c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c9fa26698a446f8ba82109d1cc3dbfc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1516fb4b208246f9b777ad4da6744345"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a65506462bfc44cbbb17e18602b17854"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f956b90ef44d467b89a90ae9b07b4444"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2bbb4fb7fb124dd5b91953d8acce306b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1b99ebcba2645d69c1e1053639bdfe1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0df51193052b48eeb76985fb8ea0071d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4deafa7599d84d62a6776e37defcb97c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56cbb8c07dfe4316bf33c29fb99f3467"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c78c9aa9e3a343048f638ad34c9de252"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b51e6de0474c4fd9bbda31ace5c37164"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dab9cfceb30e492e97323f61b06b86f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c510453086654f37a9e5a7ae07cf47d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7842a59d19484dbdb808e5797485307a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dec11c7a3b684f6fb7159e47839889f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7208d1a16292441fb73f65475f76e647"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fdf282d7084462bab2d723d65eddb83"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb3d9aaee0064d84a07220a4be0e060a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d493b2e2582b4cb98b56766cc752d745"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d9c80fc2bc245b598b3c6d798a48115"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b5bbc265cf4408a9221f4fce511a89b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c157a757773640dc9bb1f22286d3be8a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85a1cc30a5aa411497d5f6e2ce54a5fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8d7f26dadf34c0a841aaccabf3a75c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"674f187df2bb4463a5591d1edfac2197"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5800d653830b46528a747997c0a804b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03f7d044438a4a66a457e8e8693e39e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f44268e1ceb4920ba635bace9538747"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8745e94836e49d5b0a63fac88706c41"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"241b5463d63441fdbc460394bbb24b0c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f60fab07db7493893218c7a4091af98"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"295c2f8364dc47f99358a0a3a3c74d13"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e96ea4b998664ff184fa56ab48f043a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6a420c18a6447e68384c91f6fad669e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8165b440c01473f9146fd0f95c4c9dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f3226a9717f4793822f46cffa814fcc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e88f9b58854f44c4a345e8b77dd22a76"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c21c3cf9e75f4caca26a8e785d7ab6cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d9e2b8006f243eba2a265e2e0607ad6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"149dfd0d339345b0aa0ec8b2c93baad6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7abbfaa5b0fd43d1aac3ed158aa714a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98cbc5ff9a594584876409b7e1cecf2b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ade9674c3ad84f83931c1e047fa41fe7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"439d1047db78425a95ebe5c000c67af2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ce1e3ef414a4cf390302d0c515a4e6b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9b97aca2b82432eaacccfbaaf5adbfa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"414c33f9093a4d658550c2502111c71b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f265fce652e54c9898f56a9b8c844b75"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c33723ade5044fdb718413b28fc19db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46f724d3911f427e9a4cdeb377e7ee19"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b92dc6219b694037bf791f12ceecf84e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34ce214d80964492a7e9097c6f0026fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7e3313f420d4af5ad2926f34e4d010d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e1b2f60711c44d6a1f425419fea1605"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"449de83ab31540749aac08feb0674789"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c970129dfcf4705835672e44aded809"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9d41f7ba32b4414ae7933bcb4edcb90"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8bb8b6dbd4e94785ab8adeba70a3c12b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fb77f094da14fd7a0ecc91a7c9c6f97"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c115a4052fa47ba9daa76365e4d9562"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ffbcdffbc0ae49b1a5c969d5c6049848"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"073310a5a5fa4f4d96d897ad8731f2ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cbfab2cf1a874c0bbfb493db5d640137"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f11b687fee8402ab08dd417ca2a8533"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89e8810260a8406b9d0799adb7efb28b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55a17945c2764c529cc50998414f4f19"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6ee15666fb44ba78a16eb67b1e1adbe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d1335ad2279432784dcc380ec80ffd2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc899e58a9e74c78a3efddb481f35542"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25f2b0f9aaea422c8649931ff72b8645"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c38d368fe2443d198319942dd603ac5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"245186e52cba4c34880f10a77f9a835c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"001793722d3c477b932d5ed77c3137ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ecc47b287ce445083b44074d78f60d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0772d6788a3a46248cf5e8004e62eadf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4cc9e6bb6b6949ea8d7b82dd4633be0c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fff1aec19bf4cdb8d74d8dca68a2d79"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d2ad6e56fac4cad9b2889c43f64288e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44a775c865034566876dd6eece8ce0a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"532b517d5d7e4bb0b54007661f422625"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c4869d0105d4f6a854d0512a4084522"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18bfc69468c2421dbb85262072e782c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe733e21cfc2418990e88adadc028065"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"562a5ce423e545c7be7cb27a5612ee56"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"848877c5ebf746eaab8c717f4bc28af5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"629067c23ecd4fa6a983286a48679515"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6535e25404a34886b904b45ede836787"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4fcbf946de64087b8369f0e714a1f53"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f384591e31cf4f6284e980bc9380c7ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f69dc5120d0941b28f7c2815bc39da60"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b7028188b874ae5813b0c4eef19c276"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08c0e31d026d4d50b06dcbcee3ac2ec9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56c42ff1379849498cd35bed75234b25"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a58011af97814327a2c776f1eb3bbdc6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fd61658c1ea4354a5f245bdce236d02"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa84854436834381887cf6f5fe061ab9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cbdeb39d9ae445918271edc7f36b6540"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff95af138b244081a0015ec9c6ae5e75"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec017a81a8744e938789ce22ee02b2bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00a03782068342ec83117dc3e5885444"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1364c15d00394d48b8b083ce0150d590"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6214dc6c92e94939a9caa7d665a5a16f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88f99943a3e6479c97f0a6e07b9404e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53790a2b0f12450ea15b50446ec7ff22"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"338b2c2e751c49698620e180a981bc0d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af9d9b7404b84fa3b7917e908dfb74ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca0b664f6a144f7cbceaaa1df9f7c844"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0af9f193aa404dd6be8ca7559b934d2f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad8332d1c03c44e2aa177a8769be1150"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b7f3ee887c34a5f9efe34aa4c5c0488"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"932cc3d76e554a5abb27dccf145f6b76"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9379676f5ba74378b3ce9b59b456d63f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2a280cc5b1f4a23b57474a36a89428e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73e0be29863546cba82111d025d0f592"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb1ef445647642e9a22e8f25d9474d27"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48631a42584e429da52c89cbdae20d7b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af54640f1182440fba46379b3c3c526c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ea24f9791a04d44a94dcfd092b6b901"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ca8e67b8c904df79c45a9915c21f770"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6d9e6d21f574e97ad77497604c5c5b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14bc95a077f841848f04e98f9951406a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"708d26cc7886482992cd5e164d30ecab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d59220a5bcb947c8ae62cd5bcc1a2738"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1b15da4637d437e8a29d9d75c35ac55"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2ab9673556d4a35b9df731946f2a858"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05e3f085464f4501826fd3e8348e6e8b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c8a37ec61a3441384fcee75c449ef6c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e0bd08ee0d24b0f984171027f0f8fe9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7cf779d1efd446a38371842ccfdbc8e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82286e1e63064e2c8713b2bcfb908328"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"447e3e624bcc4482951ec9074a50b0a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e562a787f5e84a41bb32d2c8fcf7450e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a297a3207e3a47269ea7c47e0772a8ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b162fdeb67ad4fc2885b182a417db3c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98a89853ecb8422c97b5e86c80939232"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e711d661961a448881aacfb38dc916a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b5d95623ba74b9abe2c5332856ae422"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b25217fa1604d4d9312845c8667fb2a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b87d0218c854f049f4bae73f8fa2f4d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27364cd7f31c4cbca1f7f4b92a237965"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4588f2fa5fe40ae9b79f74b29d27200"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a93c93b450fa4382a655ced6b0d510ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"516b0177c0ba4e248cf7c352215a22d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5bf4848d16e347d0a5eeb68c5a9f4909"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d17ebf6a8c042888ca1f82368d66de1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a13b767900244dea953fac15f7f27e21"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3855fa3bdfc4b32826a417924ef6cf0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d417ff018f44b79b1a1999ffdf18058"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ed6e536b8ba43a592755f1fb4f38226"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2c91e5f630b47b28c265045b24771ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4da198410004527b979a453ed843227"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83ee101561b6401e9547f820b32f64d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dcb102e111a04622bcf8b9ccf77af46e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7009a3ba8119413c8877147a5c07b69e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"730656e8a2a94c948bd91a7d03bf7de2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"644532de4fc740068fc078fcd92d8f26"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"baf1658dcebf46e4af7662b3a67025f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7379353216f42a9b363928ac7aba43a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6908caa5e344d68adafef2ebec88e87"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3113dae347d24e67b7ccd60d1d234978"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08fb50db32984bffad3fda7b8de81379"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a4afbc127a04df3950e6c8e0cce1b07"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ae301b6304946febde79e8d7eafb939"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7a89b68ed4140caa8765fb643bd477d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d9148f50518419b80d11298a08a175d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb39ca9ee7c04ec89732d242707757a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"261fb0284f1e47db91466b9ca0f6a631"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e56064b301724b618d9b7fda20b40107"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee24de06bd6743c2ad569d494ef6c259"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ccce05686ca4db1afb4ea0ac6cfa975"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee4a86fd6e8b4e9fa353b82a3596bd66"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4685bc35d51a4b04bd7af1dc5b29c11b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c37e202f5f3b4ea6ac052277da6cd55e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d459dfeeec7541aca4de82e032151db4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2ef4a488bc34ea9825f50c3d021c438"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e8cb0708af944559534de23d0732a83"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d495622222d040168d05f37d999f4234"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7afdabec6a9849738d5f59cf014c3cf1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1dbeab949bb84e3c9c18072bfcad0f90"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ee2e4f850ad4bf184f6e338f040a242"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9982bd455c2e4e3daab06c70c58b51c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97849e3d8dec4a6da8f92294210fb417"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8a8b1190a2a4c409bf6bce6b0486505"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7c66315c5b0423bbe80cc586853c120"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c428ed9614c48d3a6447e6dc8799891"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a80cbf8351ed4efcbeae6413980660e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ee2debaf64e46a4a63e33b1131f1cb9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f07208f0084464484e4eee0ccb09ee4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6d622c89b4646cebd9c1643dfa0b219"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84bcf6c995584ead9dd815608d1de27b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80054ebaf0fe483b93d349e8d0b34abb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3102395805be4c8bb75de3b2a484209c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4f7a9ff741e481cbde596045dcb9ee3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e1dd4ad2de64ab0ad4136a71cac3a18"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0fc04f584e543538cbd3d4147336729"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5cf5390363e54beebb2012e5d0c877a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1754bdb5b9e44d294722a9d48b40a39"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1e5b6325696436e91d9f5e0c46f7f40"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83150cb672f7436ab1af4549d5e884bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3776633d1dec4ce292abb54c0463d9f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24ed88a90c2b48f99a2455fad54eda29"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af91b223aaf4418e949341e1472399fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2daa9f163a0e417ca90bf4fff21d97da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0c704b62cf84c08968186cda7c890bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb3876911c34433b9e1c2b642ab32acf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8db2ef5f6de3412a9d06445972f49314"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e77cbcb545da44a195007104052d89b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f07a2fe09d5450cad4fc43acf0c04aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b9f85dda05146019f0c01287a22a8c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fc72d0a8447490c800b6cad72179c0e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"627745e2dd6e4143813a2ee88c11b86f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f52942fb16343c786203772e95345a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9218c7e7840e4e09b8fb2841d62c6e00"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80601b91c774402f85afc1e5e278261c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e55133101a446cb8c462841ced9cb1f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fd6056b8e484735ac163dc9880175e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"053bda83d1d74b5e969b63b86da41a8d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0d33cd4899b42b093b5e1e490cf6a8e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18ff983114704c2fb255339d93335896"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f8de4dd62014304b1764cd8d46bcbb2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97e1defe5d4748af851dbd55e7cc859b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9f1da5d6abd41888704dc582a36b8cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d16925c37c9240b8a2d2b3dd57d2f493"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0994d90dbab44d1f9dfcde5fc025d4b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fc1124fb3a946d2bf585f2c9a8b6a46"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"084973b844974632becd39d305dc204f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06fc2b8d635e4cb2ac456918eb4a3b64"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"783c76dd450146bfa8af4513e77c846a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3325f0a8a914151a2da6576a87963d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7048d10740694f058290134ce8bfdd35"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87d70f0e15b845d1bf36084960981383"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"885c59568cf8490e871582f85e00b1ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76b60a9b940a4da9a0a9463da7d3185d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"041f14d148ec4e12b911a974942898f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87a14a8344584fbc9a75e333ebe48299"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2230da6a270488aa267c84353dc3c1e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0702f8e1711940619d231b14f0033b62"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23f1b930fdda45c68658aa0017b92eb6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d3d6f2e54404afb9960ffb6b4368dc4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61948bf572b642c5886d74bf9f4af8c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3cf261928a6450680658fbde2f06912"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f52db964ff34e67a728ff3bee7dd750"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95ad71ee568844218a038be3a0912634"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8946474e49c46089cd5bf2311ed3486"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"390299275764415192af28144548166a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c2bd78a2c33495f8f80c83f9c001a46"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c57096c555604b6d983ed4a068705141"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"969af7a6d39749faaa66244d6475f814"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4783c7874f54119b3ef385e2c4c9408"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2af7cd0de34a497ea9b0c583f3516559"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f44969a9eb6344b5acd9e598af232d20"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c2d99a157fc4d359e604e3e5a07abb5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"473fdd66bd994041866da7f0ad579708"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0ee289887144ac3af53102bb6f06f91"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb8869dacb2a4c9f8444810ed14c6995"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7091e09f9ae748a0b208b5c756cddece"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1acbf4c7b4854ad18eb2dff3e7ec4879"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91abbd26e5754901ae760d644e1d6d76"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a5c545e4cc24980b444defafaf9d852"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"200998790db04850ab0511db334c4f7a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99552b85a2c5425cb7fcf5f13db653ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f62b64623fca45a9926e1973f1c3418e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62d64eb34c44413c98723e039e6abe96"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c453439b706f401da690a3405970ee12"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29e11e2f7f584e2499bb9e849282f64d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f8fed3b2e1b407cafe3c83909c892c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0aaf8787ec3a4ef8819b78fb69770e82"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a87390457c4452dac80d491cfd1a93d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eaaa37ad774a4490a6aa7a96ee21782f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d0065069927443bbb0f544710f9d816"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86d66610f23d46b6a95799afed58b889"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ae8158ca0c1455a9d072fa773686bba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43f79cb1f03c414bb01851a13c3660bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0a03eca79e84baf975378b31b281363"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05486f6c607b48f798b422ddeb60b5b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94d5f3cc769c4cf5ad95dbf6b7dac1d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b32e108d06e7426887dd70b312a9a20b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"161e9396290d41beaae2ce742cdd2ccf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9ddd47da192409b99db413ef2b08ee6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc99e08301d5404cbdb70fb479a1d796"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c87eb48d02224248acac630731035f30"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b7a29c659374c23b6aa9b1cc578c34d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbe6e83351e74435bec671085b77aa4f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e05651be288e48c2859d3086b7f4af04"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b72ef4edc314ec4aabbec94c0a85c0e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72b795696e9f43e1b2704b89d239224b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9962571d6e3d40919f7010ab434d2ed8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4dd05b10f2504acf8e4d146ab38f0f7e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86dbb18dc3594cb7aea4f706714a288f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b46beb5c17942de8ead28de124a33dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95b95a43c20b4f1aad29b45bc220d836"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd5d2f2a81a944ab923eb63bc6ff621e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5cc35bccb5be40e48a55885d50d9d66e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7c3e1941af040b08d25f515b3b9266f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28f60b02d197455cb7ef177050a94e21"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c4d187232474425876d408fce9847c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dcbbbf6fa7984e2ca281fa4b8a70211d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"162b3584f4cc420b8f4bbc8503622d04"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4f0ed99b4a3460b8d3097bbef5477b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"227f4287085f401d98978d9dedcc32d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7566b32d5dfb4926b7f4df17d07bff4a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ca8e26832444f33924752f84abe7126"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b9c0cb2e4fa4d288886e2c7770bc5a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fcc7867d033541b4b28119471c8cb61a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5896e55711424174a999c9c3d134a1ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f05eb45b0c4d45ad8f74aebc36380d98"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df3f401f01c44a75ae47c5d25a0efc7f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"737705e393584bf5b80a7cf05a873a9a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56af23928a634e5fa0b8c8225fb4d9c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7a9d03126b94bdcbf8174670c8e3bfb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1bfc36fef9148f48c267ec9cd9a54f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"454ebb14622c4eb3a438829bd5344376"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d326ad0005044fb8af3ce6a3566a3a83"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1dde1838f26b403d98890efd303d0176"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebf44eadaaa64ed584d83a7e777329dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72d2a0a4286a40aabc2566c075da07ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74275a06d9a84aeeaf4ea7c6679b9a4a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afec2ce8ddcf40978fc91b402c9ccc53"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8b71f46dd56491abb6ab77a4d377034"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85a3c7aaac1b431896d758ba2990d9b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb1e73ab6bb84d5a8edb89bc297d0505"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"528a67a0b6f44636b645c037b5acaa8d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d110bef3218a4cf08401dc7c92b65c00"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07732d26160640b2b9a01b7d552251ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2aaf77762460460d8277f9dd72d78455"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80136e47b84347088d3837806b3e17f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccd4462e30e844439ec9430abe8694cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c7037ea5c734a91a0b770a8cce0ce80"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"172f8a5e9b9d462781c9f8f41aca97bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5dcb9a6ba1654d829988e100ba032733"}},"metadata":{}}]},{"cell_type":"code","source":"print(len(inference_data))","metadata":{"execution":{"iopub.status.busy":"2024-10-22T12:54:03.300635Z","iopub.execute_input":"2024-10-22T12:54:03.301655Z","iopub.status.idle":"2024-10-22T12:54:03.306693Z","shell.execute_reply.started":"2024-10-22T12:54:03.301610Z","shell.execute_reply":"2024-10-22T12:54:03.305827Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"440\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Load Base Model","metadata":{"id":"7RCE3fdGhDE5","papermill":{"duration":0.008892,"end_time":"2024-02-21T09:38:17.316544","exception":false,"start_time":"2024-02-21T09:38:17.307652","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from transformers import pipeline\ndevice = 0 if torch.cuda.is_available() else -1\ntext2text_generator = pipeline(model=\"mrm8488/t5-base-finetuned-question-generation-ap\", device = device)\ntext2text_generator = pipeline(\"text2text-generation\")\ntext2text_generator(\"question: What is 42 ? context: 42 is the answer to life, the universe and everything\")","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:31:05.606005Z","iopub.execute_input":"2024-10-23T11:31:05.606730Z","iopub.status.idle":"2024-10-23T11:31:08.196217Z","shell.execute_reply.started":"2024-10-23T11:31:05.606687Z","shell.execute_reply":"2024-10-23T11:31:08.195351Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stderr","text":"The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\nThe `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\nThe `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\nThe `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\nThe `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\nNo model was supplied, defaulted to google-t5/t5-base and revision a9723ea (https://huggingface.co/google-t5/t5-base).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\nHardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n","output_type":"stream"},{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"[{'generated_text': 'the answer to life, the universe and everything'}]"},"metadata":{}}]},{"cell_type":"markdown","source":"## Inference before fine tuning","metadata":{"id":"G_L6A5J-1QgC","papermill":{"duration":0.010947,"end_time":"2024-02-21T09:39:10.55264","exception":false,"start_time":"2024-02-21T09:39:10.541693","status":"completed"},"tags":[]}},{"cell_type":"code","source":"print(inference_data[50])","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:31:01.305981Z","iopub.execute_input":"2024-10-23T11:31:01.306854Z","iopub.status.idle":"2024-10-23T11:31:01.312892Z","shell.execute_reply.started":"2024-10-23T11:31:01.306700Z","shell.execute_reply":"2024-10-23T11:31:01.312009Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"Instruction:\nWhat is the main architecture used by GreekBERT?\n\nContext:\n\nand NLG tasks. GreekBART (Evdaimon et al. 2024), based on the BART architecture (Lewis et al. 2020a), was pre-trained on the same datasets as GreekBERT plus the Greek Web Corpus (Outsios et al. 2018), incorporating diverse Greek text types, as well as formal and informal text, to enhance robustness. The GreekT5 series of models (Giarelis, Mastrokostas, and Karacapilidis 2024) were fine-tuned on the GreekSUM training dataset (Evdaimon et al. 2024), using the multilingual T5 LMs, which comprise (google/mt5-small (Xue et al. 2021), google/umt5-small (Chung et al. 2024a), and google/umt5-base (Chung et al. 2024a)). 19https://dumps.wikimedia.org/elwiki/ 20https://commoncrawl.org/ 13 Table 5 Monolingual Greek PLMs, including their availability (Yes: publicly available, Lmt: limited availability; tags are linkable; see Table 3 for details) and the backbone model they are base on. AUTHORS AVAILABILITY BACKBONE Giarelis, Mastrokostas, and Karacapilidis (2024) Yes mT5 Yes umT5 Yes umT5 Evdaimon et al. (2024) Yes BART Koutsikakis et al. (2020) \nTjortjis 2022; Evdaimon et al. 2024). GreekBERT uses the BERT-BASE-UNCASED architecture (Devlin et al. 2019) and was pre-trained on 29 GB of Greek text from the Greek Wikipedia,19the Greek part of the European Parliament Proceedings Parallel Corpus (Europarl) (Koehn 2005), and the Greek part of OSCAR (Suárez, Sagot, and Romary 2019), a clean version of Common Crawl.20There are two fine-tuned variants of GreekBERT: Greek Media BERT (Zaikis, Stylianou, and Vlahavas 2023), which is fine-tuned on media domain data, and GreekSocialBERT (Alexandridis et al. 2021), which is fine-tuned on Greek social media data. Additionally, PaloBERT (Alexandridis et al. 2021), trained on social media data, and BERTaTweetGR (Perifanos and Goutsos 2021), trained on tweets, are two monolingual models based on the RoBERTa architecture and they address also NLU tasks. On the other hand, there are two monolingual PLMs based on the encoder-decoder architecture (see §2.2), which are capable of performing all NLU \nApplications and Innovations , pages 60–73, Springer. Giarelis, Nikolaos, Charalampos Mastrokostas, Ilias Siachos, and Nikos Karacapilidis. 2023. A review of greek nlp technologies for chatbot development. In Proceedings of the 27th Pan-Hellenic Conference on Progress in Computing and Informatics , pages 15–20. Giatsoglou, Maria, Manolis G. Vozalis, Konstantinos Diamantaras, Athena Vakali, George Sarigiannidis, and Konstantinos Ch. Chatzisavvas. 2017. Sentiment analysis leveraging emotions and word embeddings. Expert Systems with Applications , 69:214–224. Giorgi, Ioanna, Bruno Golosio, Massimo Esposito, Angelo Cangelosi, and Giovanni L. Masala. 2021. Modeling multiple language learning in a developmental cognitive architecture. IEEE Transactions on Cognitive and Developmental Systems , 13(4):922–933. Giouli, Voula, Vera Pilitsidou, and Hephaestion Christopoulos. 2020. Greek within the global FrameNet initiative: Challenges and conclusions so far. In Proceedings of the International FrameNet Workshop 2020: Towards a Global, Multilingual FrameNet , pages 48–55, European Language Resources Association, Marseille, France. Goddard, Cliff. 2011. Semantic analysis: A practical \ndatasets available upon request; see Table 3 for details), annotation type (see Table 4 for details), size, and size unit. AUTHORS AVAILABILITY ANN .TYPE SIZE SIZE UNIT Mountantonakis et al. (2022) Lmt MANUAL 200 QUESTION -ANSWER PAIR Lopes et al. (2016) Lmt MANUAL 200 DIALOGUE 12.3 Summary of Question Answering in Greek Reflecting on the available QA LRs and architectures for Greek, several key observations arise. First, there is a clear scarcity of QA resources specifically designed for Greek. To confirm this, we conducted a search in the Hugging Face repository for Greek QA datasets, which revealed 20 datasets containing Greek. Of these, 18 were multilingual, making reliance on such resources essential for advancing Greek QA tasks. Moreover, these datasets were predominantly translations from English. However, a limitation of these multilingual translated datasets is that they do not offer representative samples of Greek questions. This is consistent with the observation \nwith XLM-R, two variants of mBERT, and the Decomposable Attention Model (DAM) (Parikh et al. 2016). They found that GreekBERT outperformed the other models. Three years later, Evdaimon et al. (2024) fine-tuned their model, GreekBART, on the XNLI training split and compared it with GreekBERT and XLM-R on the test split, concluding that GreekBART achieved results comparable to GreekBERT. Discourse Analysis. The only study identified that performs Discourse Analysis is by Giachos et al. (2023). This study focused on how the robot processes and understands sentences in context, teaching the robot to handle incomplete information and enabling word learning procedure, starting with 200 Greek words as a seed dictionary. 20 6.2 Semantics in Greek: Language Resources Table 7 presents the LRs for semantics-related tasks, along with their availability (classified according to Table 3), annotation type (classified as per Table 4), linguality type, size, and size unit. By contrast to Syntax \n","output_type":"stream"}]},{"cell_type":"code","source":"instruction = \"What is the architecture of GreekBERT?\"\ncontext = \"\"\"GreekBERT uses the BERT-BASE-UNCASED architecture (Devlin et al. 2019) \nand was pre-trained on 29 GB of Greek text from the Greek Wikipedia, the Greek part \nof the European Parliament Proceedings Parallel Corpus (Europarl), and the Greek part \nof OSCAR, a clean version of Common Crawl.\"\"\"\nanswer = text2text_generator(f\"question:{instruction} context: {context}\")\nprint(answer)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:31:13.481334Z","iopub.execute_input":"2024-10-23T11:31:13.482004Z","iopub.status.idle":"2024-10-23T11:31:14.037822Z","shell.execute_reply.started":"2024-10-23T11:31:13.481966Z","shell.execute_reply":"2024-10-23T11:31:14.036812Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"[{'generated_text': 'BERT-BASE-UNCASED'}]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(inference_data[1])\nanswer = text2text_generator(inference_data[1])\nprint(answer)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:31:15.785576Z","iopub.execute_input":"2024-10-23T11:31:15.785935Z","iopub.status.idle":"2024-10-23T11:31:18.928074Z","shell.execute_reply.started":"2024-10-23T11:31:15.785901Z","shell.execute_reply":"2024-10-23T11:31:18.926999Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"Instruction:\nWhat is the purpose of the quality assurance check?\n\nContext:\n\nas it goes through continuous improvement cycles ( I1,I2,I3,I7). The goal is to quantify the occurrence of fairness issues ( I3) which may be valuable information for an audit. With every new model or change in data or parameters, the fairness dimension of the system may be affected ( I2). Interviewee one mentions the importance of standards that can be systematically checked with every system retraining ( I1). Such testing could be run at a very granular level assessing, for instance, confidence and explanation scores on a sentence level as a foundation for later judging fairness ( I2). Passing scores or red flags should be established for fairness test sets to make the fairness testing impactful ( I2,I3). Interviewees are divided on how automated such testing can be. While interviewees one and nine see potential in automated fairness testing, interviewee seven argues the process is not automatable as there is \nFor instance, in question answering, responses that contain insensitive or stereotyped content could be avoided ( I10). A wide variety of fairness metrics are also represented in different definitions of fairness available to choose from ( I8,I12,I14). No matter what metric is used in the end, its impact on the technical system must be assessed, and its suitability and implications for the use case must be assessed ( I1,I8). 42 Freiberger et al. B.6 Operations Criteria Bringing a system into operation and going through continuous improvement cycles to maintain its quality should be investigated in a fairness certification process. These steps in the lifecycle determine whether a system will maintain fairness over time ( I9). Fairness can deteriorate in operations, for instance, at the cost of performance ( I2). Interviewee six mentions that the certificate must maintain integrity over time ( I6), which supports the relevance of system operations criteria \nthe system ( I5). Evaluation Evaluation is essential for assessing a model’s fairness ( I3,I7,I9). It involves testing the model or the system it is embedded in regarding various targets or metrics. Reproducibility must be given for company internal evaluation processes so they can be assessed in an audit ( I8). A challenging factor may be the definition of fairness which is the foundation for evaluating fairness ( I8,I12). As the definition of fairness differs between the auditor and all affected stakeholders ( I12), a hierarchical approach to evaluation focused on the system’s stakeholders may make sense as a base- line for evaluation ( I8). Another challenging factor is to be found in the context of data as a prediction foundation. Sometimes truthfulness or accuracy may be questionable but hard to verify, posing a major issue for evaluation ( I8). In open-domain systems like question-answering systems or recommender systems delivering \nsystem testing for potential issues in a set time interval. The so-called “red team” is to find fairness vulnerabilities in the system. That could be seen as an exemplary holistic and focused company internal fairness assessment. Such assessments Fairness Certification 29 are typically motivated by ensuring to be regulatory compliant with future legislation besides ensuring fairness ( I14). These assessments or internal audits should take place continuously ( I7) and should not be conducted by the development team but rather by a separate organizational instance ( I14). An aspect that may be assessed which may vary in its importance for fairness between use cases, is the amount of human oversight in operations ( I4). One more dynamic should be considered regarding accountability which addresses binding claims made by a supplier about his product that shift re- sponsibility back to the supplier ( I1). An assessment should also check the diversity \nInterview partners came up with six concepts relevant to this which are validation of predictions ( I1,I4,I6), involving affected stakeholders in evaluation ( I5), adversarial testing ( I1,I4,I7), data sets or benchmarks for testing ( I2,I3,I6,I8,I9,I11,I13), criteria focused on human- computer interaction ( I2,I7,I11) and ethics criteria ( I4,I11). Another important consideration for evaluation is what metrics should be utilized to test a system’s fairness. Interviewees name metrics focused on robustness or generalization as an essential element to measure the model’s likelihood of generating unexpected, unfair results ( I2,I4,I8). Impact-based metrics depend on the chosen fairness paradigm ( I3,I7,I8,I12,I14). Another approach proposed by I10introduces a metric that penalizes the model’s use of sensitive attributes or unethical content when calculating loss. Operations Criteria center around what should be considered regarding fairness when deploying a model and what mechanisms must be implemented to maintain fairness over time. That subsumes three sub-codes. Sub-code \n[{'generated_text': 'False positives and negatives are important factors for evaluating fairness . '}]\n","output_type":"stream"}]},{"cell_type":"code","source":"for i in range(len(inference_data[:10])):\n    print(\"Question: \", test_data['question'].iloc[i])\n    answer = text2text_generator(inference_data[i])\n    print(\"model answer: \", answer[0]['generated_text'])\n    target_answer = test_data['answer'].iloc[i]\n    print(\"Target answer: \", target_answer)\n    print(end=\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:31:25.553545Z","iopub.execute_input":"2024-10-23T11:31:25.553931Z","iopub.status.idle":"2024-10-23T11:32:03.070988Z","shell.execute_reply.started":"2024-10-23T11:31:25.553891Z","shell.execute_reply":"2024-10-23T11:32:03.070026Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"Question:  What is the main topic of the text?\nmodel answer:  a saturday night in california was a day of\nTarget answer:  The text does not explicitly state a main topic, therefore I cannot answer this question.\n\nQuestion:  What is the purpose of the quality assurance check?\nmodel answer:  False positives and negatives are important factors for evaluating fairness . \nTarget answer:  The purpose of the quality assurance check is to ensure the accuracy and completeness of the retrieved records.\n\nQuestion:  How many bibliographic records were retrieved?\nmodel answer:  a total of 1,717 bibliographic records were retrieved, which were reduced to 1,\nTarget answer:  A total of 1,717 bibliographic records were retrieved.\n\nQuestion:  What metadata is included in each record?\nmodel answer:  aCL Anthology (AA) contains 209m papers and 2.5b citation\nTarget answer:  Each record includes metadata such as the title, author names, abstract, and publication date.\n\nQuestion:  What is the purpose of the filtering strategy?\nmodel answer:  3.2. Search Strategy We formulated our search strategy to retrieve the maximum number of relevant studies\nTarget answer:  The filtering strategy is used to reduce the number of records by removing duplicates and filtering based on the specified criteria.\n\nQuestion:  What is the main topic of the text?\nmodel answer:  a saturday night in california was a day of\nTarget answer:  The text does not specify the main topic, therefore I cannot answer this question.\n\nQuestion:  What was the process of excluding papers?\nmodel answer:  79 Table 1 The number of papers retrieved from Google Scholar during the quality assurance search round\nTarget answer:  The process of excluding papers was based on the number of citations and the year of publication.\n\nQuestion:  What was the impact of the citation threshold?\nmodel answer:  citations are higher for papers introducing new datasets than for those proposing new tasks\nTarget answer:  The citation threshold excluded papers with fewer citations than the defined threshold.\n\nQuestion:  Why was Google Scholar used to count citations?\nmodel answer:  citation graph of 185,384 papers . citation graph of 185,\nTarget answer:  Google Scholar was used to count citations because of its high coverage.\n\nQuestion:  What was the final selection of papers?\nmodel answer:  142 papers were selected for our paper selection process . a.1.2 Background/Lite\nTarget answer:  The final selection of papers was 142, all published within the selected time frame.\n\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install evaluate\n!pip install bert_score\nfrom evaluate import load\nbertscore = load(\"bertscore\")","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:29:07.114166Z","iopub.execute_input":"2024-10-23T11:29:07.114894Z","iopub.status.idle":"2024-10-23T11:29:32.260244Z","shell.execute_reply.started":"2024-10-23T11:29:07.114852Z","shell.execute_reply":"2024-10-23T11:29:32.259480Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.0.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.25.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (24.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.15.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting bert_score\n  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from bert_score) (2.4.0)\nRequirement already satisfied: pandas>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from bert_score) (2.2.2)\nRequirement already satisfied: transformers>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from bert_score) (4.45.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bert_score) (1.26.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from bert_score) (2.32.3)\nRequirement already satisfied: tqdm>=4.31.1 in /opt/conda/lib/python3.10/site-packages (from bert_score) (4.66.4)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from bert_score) (3.7.5)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from bert_score) (24.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert_score) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert_score) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert_score) (2024.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (2024.6.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (0.25.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (2024.5.15)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (0.20.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (1.4.5)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (10.3.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (2024.8.30)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->bert_score) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.0.0->bert_score) (1.3.0)\nDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: bert_score\nSuccessfully installed bert_score-0.3.13\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/7.95k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ae057c17057469f9db4e37890cc6f7c"}},"metadata":{}}]},{"cell_type":"code","source":"predictions = [\"a saturday night in california was a day of\", \"general kenobi\"]\nreferences = [\"hello world\", \"general kenobi\"]\nresults = bertscore.compute(predictions=predictions, references=references, model_type=\"distilbert-base-uncased\")\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:32:14.451563Z","iopub.execute_input":"2024-10-23T11:32:14.452397Z","iopub.status.idle":"2024-10-23T11:32:14.480997Z","shell.execute_reply.started":"2024-10-23T11:32:14.452356Z","shell.execute_reply":"2024-10-23T11:32:14.479769Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"{'precision': [0.595603346824646, 1.0], 'recall': [0.6710658073425293, 1.0], 'f1': [0.6310867071151733, 1.0], 'hashcode': 'distilbert-base-uncased_L5_no-idf_version=0.3.12(hug_trans=4.45.1)'}\n","output_type":"stream"}]},{"cell_type":"code","source":"predictions = []\nreferences = []\n\nfor i in range(len(inference_data)):\n    print(\"inference example: \", i)\n    answer = text2text_generator(inference_data[i])\n    predictions.append(answer[0]['generated_text'])\n    \n    target_answer = test_data['answer'].iloc[i]\n    references.append(target_answer)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:32:21.337608Z","iopub.execute_input":"2024-10-23T11:32:21.338007Z","iopub.status.idle":"2024-10-23T12:04:03.940611Z","shell.execute_reply.started":"2024-10-23T11:32:21.337970Z","shell.execute_reply":"2024-10-23T12:04:03.939729Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"inference example:  0\ninference example:  1\ninference example:  2\ninference example:  3\ninference example:  4\ninference example:  5\ninference example:  6\ninference example:  7\ninference example:  8\ninference example:  9\ninference example:  10\ninference example:  11\ninference example:  12\ninference example:  13\ninference example:  14\ninference example:  15\ninference example:  16\ninference example:  17\ninference example:  18\ninference example:  19\ninference example:  20\ninference example:  21\ninference example:  22\ninference example:  23\ninference example:  24\ninference example:  25\ninference example:  26\ninference example:  27\ninference example:  28\ninference example:  29\ninference example:  30\ninference example:  31\ninference example:  32\ninference example:  33\ninference example:  34\ninference example:  35\ninference example:  36\ninference example:  37\ninference example:  38\ninference example:  39\ninference example:  40\ninference example:  41\ninference example:  42\ninference example:  43\ninference example:  44\ninference example:  45\ninference example:  46\ninference example:  47\ninference example:  48\ninference example:  49\ninference example:  50\ninference example:  51\ninference example:  52\ninference example:  53\ninference example:  54\ninference example:  55\ninference example:  56\ninference example:  57\ninference example:  58\ninference example:  59\ninference example:  60\ninference example:  61\ninference example:  62\ninference example:  63\ninference example:  64\ninference example:  65\ninference example:  66\ninference example:  67\ninference example:  68\ninference example:  69\ninference example:  70\ninference example:  71\ninference example:  72\ninference example:  73\ninference example:  74\ninference example:  75\ninference example:  76\ninference example:  77\ninference example:  78\ninference example:  79\ninference example:  80\ninference example:  81\ninference example:  82\ninference example:  83\ninference example:  84\ninference example:  85\ninference example:  86\ninference example:  87\ninference example:  88\ninference example:  89\ninference example:  90\ninference example:  91\ninference example:  92\ninference example:  93\ninference example:  94\ninference example:  95\ninference example:  96\ninference example:  97\ninference example:  98\ninference example:  99\ninference example:  100\ninference example:  101\ninference example:  102\ninference example:  103\ninference example:  104\ninference example:  105\ninference example:  106\ninference example:  107\ninference example:  108\ninference example:  109\ninference example:  110\ninference example:  111\ninference example:  112\ninference example:  113\ninference example:  114\ninference example:  115\ninference example:  116\ninference example:  117\ninference example:  118\ninference example:  119\ninference example:  120\ninference example:  121\ninference example:  122\ninference example:  123\ninference example:  124\ninference example:  125\ninference example:  126\ninference example:  127\ninference example:  128\ninference example:  129\ninference example:  130\ninference example:  131\ninference example:  132\ninference example:  133\ninference example:  134\ninference example:  135\ninference example:  136\ninference example:  137\ninference example:  138\ninference example:  139\ninference example:  140\ninference example:  141\ninference example:  142\ninference example:  143\ninference example:  144\ninference example:  145\ninference example:  146\ninference example:  147\ninference example:  148\ninference example:  149\ninference example:  150\ninference example:  151\ninference example:  152\ninference example:  153\ninference example:  154\ninference example:  155\ninference example:  156\ninference example:  157\ninference example:  158\ninference example:  159\ninference example:  160\ninference example:  161\ninference example:  162\ninference example:  163\ninference example:  164\ninference example:  165\ninference example:  166\ninference example:  167\ninference example:  168\ninference example:  169\ninference example:  170\ninference example:  171\ninference example:  172\ninference example:  173\ninference example:  174\ninference example:  175\ninference example:  176\ninference example:  177\ninference example:  178\ninference example:  179\ninference example:  180\ninference example:  181\ninference example:  182\ninference example:  183\ninference example:  184\ninference example:  185\ninference example:  186\ninference example:  187\ninference example:  188\ninference example:  189\ninference example:  190\ninference example:  191\ninference example:  192\ninference example:  193\ninference example:  194\ninference example:  195\ninference example:  196\ninference example:  197\ninference example:  198\ninference example:  199\ninference example:  200\ninference example:  201\ninference example:  202\ninference example:  203\ninference example:  204\ninference example:  205\ninference example:  206\ninference example:  207\ninference example:  208\ninference example:  209\ninference example:  210\ninference example:  211\ninference example:  212\ninference example:  213\ninference example:  214\ninference example:  215\ninference example:  216\ninference example:  217\ninference example:  218\ninference example:  219\ninference example:  220\ninference example:  221\ninference example:  222\ninference example:  223\ninference example:  224\ninference example:  225\ninference example:  226\ninference example:  227\ninference example:  228\ninference example:  229\ninference example:  230\ninference example:  231\ninference example:  232\ninference example:  233\ninference example:  234\ninference example:  235\ninference example:  236\ninference example:  237\ninference example:  238\ninference example:  239\ninference example:  240\ninference example:  241\ninference example:  242\ninference example:  243\ninference example:  244\ninference example:  245\ninference example:  246\ninference example:  247\ninference example:  248\ninference example:  249\ninference example:  250\ninference example:  251\ninference example:  252\ninference example:  253\ninference example:  254\ninference example:  255\ninference example:  256\ninference example:  257\ninference example:  258\ninference example:  259\ninference example:  260\ninference example:  261\ninference example:  262\ninference example:  263\ninference example:  264\ninference example:  265\ninference example:  266\ninference example:  267\ninference example:  268\ninference example:  269\ninference example:  270\ninference example:  271\ninference example:  272\ninference example:  273\ninference example:  274\ninference example:  275\ninference example:  276\ninference example:  277\ninference example:  278\ninference example:  279\ninference example:  280\ninference example:  281\ninference example:  282\ninference example:  283\ninference example:  284\ninference example:  285\ninference example:  286\ninference example:  287\ninference example:  288\ninference example:  289\ninference example:  290\ninference example:  291\ninference example:  292\ninference example:  293\ninference example:  294\ninference example:  295\ninference example:  296\ninference example:  297\ninference example:  298\ninference example:  299\ninference example:  300\ninference example:  301\ninference example:  302\ninference example:  303\ninference example:  304\ninference example:  305\ninference example:  306\ninference example:  307\ninference example:  308\ninference example:  309\ninference example:  310\ninference example:  311\ninference example:  312\ninference example:  313\ninference example:  314\ninference example:  315\ninference example:  316\ninference example:  317\ninference example:  318\ninference example:  319\ninference example:  320\ninference example:  321\ninference example:  322\ninference example:  323\ninference example:  324\ninference example:  325\ninference example:  326\ninference example:  327\ninference example:  328\ninference example:  329\ninference example:  330\ninference example:  331\ninference example:  332\ninference example:  333\ninference example:  334\ninference example:  335\ninference example:  336\ninference example:  337\ninference example:  338\ninference example:  339\ninference example:  340\ninference example:  341\ninference example:  342\ninference example:  343\ninference example:  344\ninference example:  345\ninference example:  346\ninference example:  347\ninference example:  348\ninference example:  349\ninference example:  350\ninference example:  351\ninference example:  352\ninference example:  353\ninference example:  354\ninference example:  355\ninference example:  356\ninference example:  357\ninference example:  358\ninference example:  359\ninference example:  360\ninference example:  361\ninference example:  362\ninference example:  363\ninference example:  364\ninference example:  365\ninference example:  366\ninference example:  367\ninference example:  368\ninference example:  369\ninference example:  370\ninference example:  371\ninference example:  372\ninference example:  373\ninference example:  374\ninference example:  375\ninference example:  376\ninference example:  377\ninference example:  378\ninference example:  379\ninference example:  380\ninference example:  381\ninference example:  382\ninference example:  383\ninference example:  384\ninference example:  385\ninference example:  386\ninference example:  387\ninference example:  388\ninference example:  389\ninference example:  390\ninference example:  391\ninference example:  392\ninference example:  393\ninference example:  394\ninference example:  395\ninference example:  396\ninference example:  397\ninference example:  398\ninference example:  399\ninference example:  400\ninference example:  401\ninference example:  402\ninference example:  403\ninference example:  404\ninference example:  405\ninference example:  406\ninference example:  407\ninference example:  408\ninference example:  409\ninference example:  410\ninference example:  411\ninference example:  412\ninference example:  413\ninference example:  414\ninference example:  415\ninference example:  416\ninference example:  417\ninference example:  418\ninference example:  419\ninference example:  420\ninference example:  421\ninference example:  422\ninference example:  423\ninference example:  424\ninference example:  425\ninference example:  426\ninference example:  427\ninference example:  428\ninference example:  429\ninference example:  430\ninference example:  431\ninference example:  432\ninference example:  433\ninference example:  434\ninference example:  435\ninference example:  436\ninference example:  437\ninference example:  438\ninference example:  439\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(predictions))\nprint(len(references))","metadata":{"execution":{"iopub.status.busy":"2024-10-23T12:04:05.864186Z","iopub.execute_input":"2024-10-23T12:04:05.864613Z","iopub.status.idle":"2024-10-23T12:04:05.871872Z","shell.execute_reply.started":"2024-10-23T12:04:05.864576Z","shell.execute_reply":"2024-10-23T12:04:05.870929Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"440\n440\n","output_type":"stream"}]},{"cell_type":"code","source":"results = bertscore.compute(predictions=predictions, references=references, model_type=\"distilbert-base-uncased\")\nscore = sum(results['f1']) / len(results['f1'])\nprint(score)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T12:04:07.975931Z","iopub.execute_input":"2024-10-23T12:04:07.976705Z","iopub.status.idle":"2024-10-23T12:04:09.077914Z","shell.execute_reply.started":"2024-10-23T12:04:07.976664Z","shell.execute_reply":"2024-10-23T12:04:09.076808Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"0.6915922276675701\n","output_type":"stream"},{"name":"stderr","text":"Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\nWarning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Fine-tune on train data","metadata":{"id":"Pt7Nr6a7tItO","papermill":{"duration":0.01047,"end_time":"2024-02-21T09:39:33.354485","exception":false,"start_time":"2024-02-21T09:39:33.344015","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from transformers import T5ForConditionalGeneration, T5Tokenizer\n\nmodel_name = \"mrm8488/t5-base-finetuned-question-generation-ap\"\ntokenizer = T5Tokenizer.from_pretrained(model_name)\nmodel = T5ForConditionalGeneration.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:12:53.556922Z","iopub.execute_input":"2024-10-23T11:12:53.557446Z","iopub.status.idle":"2024-10-23T11:12:54.364193Z","shell.execute_reply.started":"2024-10-23T11:12:53.557400Z","shell.execute_reply":"2024-10-23T11:12:54.363345Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\nThe `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:12:59.436609Z","iopub.execute_input":"2024-10-23T11:12:59.437603Z","iopub.status.idle":"2024-10-23T11:12:59.452120Z","shell.execute_reply.started":"2024-10-23T11:12:59.437558Z","shell.execute_reply":"2024-10-23T11:12:59.451011Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"            id     type                                           question  \\\n0  seed_task_0  general                                 What is Spark NLP?   \n1  seed_task_1  general           What are the main features of Spark NLP?   \n2  seed_task_2  general     What is the impact of Spark NLP on healthcare?   \n3  seed_task_3  general  What are the main challenges associated with S...   \n4  seed_task_4  general        What are the future prospects of Spark NLP?   \n\n                                             context  \\\n0  'sentences': [['Learning with pseudo-ensembles...   \n1  'sentences': [['vectors while the right side o...   \n2  'sentences': [['a sentence, the juxtaposition ...   \n3  'sentences': [['P(w i|cj)=P(cj|wi)P(wi)/summat...   \n4  'sentences': [['whose performance has been con...   \n\n                                              answer  cot_answer  \n0  Spark NLP is a Natural Language Processing (NL...         NaN  \n1  Spark NLP comes with 1100+ pretrained pipeline...         NaN  \n2  Spark NLP is used by 54% of healthcare organiz...         NaN  \n3  There are no challenges associated with Spark ...         NaN  \n4  The text does not provide information about th...         NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>type</th>\n      <th>question</th>\n      <th>context</th>\n      <th>answer</th>\n      <th>cot_answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>seed_task_0</td>\n      <td>general</td>\n      <td>What is Spark NLP?</td>\n      <td>'sentences': [['Learning with pseudo-ensembles...</td>\n      <td>Spark NLP is a Natural Language Processing (NL...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>seed_task_1</td>\n      <td>general</td>\n      <td>What are the main features of Spark NLP?</td>\n      <td>'sentences': [['vectors while the right side o...</td>\n      <td>Spark NLP comes with 1100+ pretrained pipeline...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>seed_task_2</td>\n      <td>general</td>\n      <td>What is the impact of Spark NLP on healthcare?</td>\n      <td>'sentences': [['a sentence, the juxtaposition ...</td>\n      <td>Spark NLP is used by 54% of healthcare organiz...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>seed_task_3</td>\n      <td>general</td>\n      <td>What are the main challenges associated with S...</td>\n      <td>'sentences': [['P(w i|cj)=P(cj|wi)P(wi)/summat...</td>\n      <td>There are no challenges associated with Spark ...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>seed_task_4</td>\n      <td>general</td>\n      <td>What are the future prospects of Spark NLP?</td>\n      <td>'sentences': [['whose performance has been con...</td>\n      <td>The text does not provide information about th...</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"!pip install --upgrade transformers datasets\n","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:13:02.221715Z","iopub.execute_input":"2024-10-23T11:13:02.222102Z","iopub.status.idle":"2024-10-23T11:13:26.849309Z","shell.execute_reply.started":"2024-10-23T11:13:02.222065Z","shell.execute_reply":"2024-10-23T11:13:26.848121Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\nCollecting transformers\n  Downloading transformers-4.45.2-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.0.1)\nCollecting datasets\n  Downloading datasets-3.0.2-py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nDownloading transformers-4.45.2-py3-none-any.whl (9.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading datasets-3.0.2-py3-none-any.whl (472 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.7/472.7 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: transformers, datasets\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.45.1\n    Uninstalling transformers-4.45.1:\n      Successfully uninstalled transformers-4.45.1\n  Attempting uninstall: datasets\n    Found existing installation: datasets 3.0.1\n    Uninstalling datasets-3.0.1:\n      Successfully uninstalled datasets-3.0.1\nSuccessfully installed datasets-3.0.2 transformers-4.45.2\n","output_type":"stream"}]},{"cell_type":"code","source":"print(train_data.dtypes)\nprint(train_data.iloc[0])","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:13:44.980681Z","iopub.execute_input":"2024-10-23T11:13:44.981774Z","iopub.status.idle":"2024-10-23T11:13:44.990833Z","shell.execute_reply.started":"2024-10-23T11:13:44.981725Z","shell.execute_reply":"2024-10-23T11:13:44.989968Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"id             object\ntype           object\nquestion       object\ncontext        object\nanswer         object\ncot_answer    float64\ndtype: object\nid                                                  seed_task_0\ntype                                                    general\nquestion                                     What is Spark NLP?\ncontext       'sentences': [['Learning with pseudo-ensembles...\nanswer        Spark NLP is a Natural Language Processing (NL...\ncot_answer                                                  NaN\nName: 0, dtype: object\n","output_type":"stream"}]},{"cell_type":"code","source":"print(train_data['answer'][2])","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:13:47.869321Z","iopub.execute_input":"2024-10-23T11:13:47.869705Z","iopub.status.idle":"2024-10-23T11:13:47.875516Z","shell.execute_reply.started":"2024-10-23T11:13:47.869667Z","shell.execute_reply":"2024-10-23T11:13:47.874579Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Spark NLP is used by 54% of healthcare organizations as the world’s most widely used NLP library in the enterprise.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Convert list entries in 'answer' column to strings\ntrain_data['answer'] = train_data['answer'].apply(\n    lambda x: ' '.join(x) if isinstance(x, list) else x\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:13:49.380914Z","iopub.execute_input":"2024-10-23T11:13:49.381621Z","iopub.status.idle":"2024-10-23T11:13:49.388312Z","shell.execute_reply.started":"2024-10-23T11:13:49.381581Z","shell.execute_reply":"2024-10-23T11:13:49.387338Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/2757648839.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  train_data['answer'] = train_data['answer'].apply(\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import Dataset\ntrain_dataset = Dataset.from_pandas(train_data)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:13:52.427898Z","iopub.execute_input":"2024-10-23T11:13:52.428632Z","iopub.status.idle":"2024-10-23T11:13:52.481316Z","shell.execute_reply.started":"2024-10-23T11:13:52.428591Z","shell.execute_reply":"2024-10-23T11:13:52.480366Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"print(train_dataset['question'][1])\nprint(train_dataset['context'][1])\nprint(train_dataset['answer'][1])","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:13:54.068684Z","iopub.execute_input":"2024-10-23T11:13:54.069529Z","iopub.status.idle":"2024-10-23T11:13:54.085184Z","shell.execute_reply.started":"2024-10-23T11:13:54.069487Z","shell.execute_reply":"2024-10-23T11:13:54.084222Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"What are the main features of Spark NLP?\n'sentences': [['vectors while the right side of the equation is a scalar, to avoid Fobfuscating the linear structure, a dot product is used: 22 2 Word Representation F/parenleftbig (wi−wj)/latticetop˜wk/parenrightbig =Pik Pjk. (2.24) The model keeps the invariance under relabeling the target word and context word. It requires Fto be a homomorphism between the groups (R,+)and(R>0,×).The solution is F=exp. Then w/latticetop i˜wk=logNik−logNi. (2.25) To keep exchange symmetry, log Niis eliminated by adding biases biand˜bk.T h e model becomes w/latticetop i˜wk+bi+˜bk=logNik, (2.26) which is signiﬁcantly simpler than Eq. ( 2.21 ). The loss function is deﬁned as L=|V|/summationdisplay i,j=1f(Nij)(w/latticetop i˜wj+bi+˜bj−logNij), (2.27) where f(·)is a weighting function: f(x)=/braceleftBigg (x/xmax)αifx<xmax, 1 otherwise .(2.28) 2.4 Contextualized Word Representation In natural language, the meaning of an individual word usually relates to its context in a sentence. For example, •The central bank has slashed its forecast for economic growth this year from 4.1 to 2.6%. •More recently, on ', 'acti- vation function proposed in (Hendrycks and Gimpel 2016). We want to point out that Eq. (1) is different from a typical GCN operation from (Kipf and Welling 2016). First, we only conduct one hop of neighbor aggregation in Eq. (1). A typical GCN module does multi-hops. Second, we drop Wt2Rd\\x02d used fort-th hop of GCN update in (Kipf and Welling 2016). This is because we assume that the BASE text classiﬁer modelfhas taken into account this prior and our WIGRAPH layer will not bias to prefer short range interactions. The third difference is the most important distinction that differentiates ours apart from (Kipf and Welling 2016). The graph has been given apriori to typical GCNs. However, in our work, we need to learn the graph A(see Section 2.4 on how to learn A). We can compute the simultaneous update of all words in input text xtogether by concatenating all ', 'situated in that country, the prime minister of a state is also a citizen of that state, and so on. (Giampiccolo et al. ,2007 ) QUANTIFIERS (14) P Neither leading tenor comes cheap. One of the leading tenors is Pavarotti. Q Is Pavarotti a leading tenor who comes cheap? H Pavarotti is a leading tenor who comes cheap. A No PLURALS (94) P The inhabitants of Cambridge voted for a Labour MP. Q Did every inhabitant of Cambridge vote for a Labour MP? H Every inhabitant of Cambridge voted for a Labour MP. A Unknown COMPARATIVES (243) P ITEL sold 3000 more computers than APCOM. APCOM sold exactly 2500 computers. Q Did ITEL sell 5500 computers? H ITEL sold 5500 computers. A Yes Table 4: Examples from Fracas: Prepresents the premise(s), Qrepresents the question from FraCas ,Hrepresents the declarative statement MacCartney (2009 ) created and, Arepresents the label. The number ', 'information extraction stemming, stop-words elimination had been used and MetaMap is used for feature extraction under the NLP. Information extraction from medical journal and publication is used to be of important use, a combination of the NLP and machine learning yielded very promising results in research conducted by [4]. These concepts had been extracted through the Unified medical language system (UMLS) database utilizing NLP system applications such as bag -of-words. As per the r esearch, NLP concepts such as Biomedical concept representation is used for biomedical concept identification. The author selected a journal research article published in pub -med for extracting the information from text articles. 278 Computer Science & Information Technology (CS & IT) NLP facilitates knowledge management through the detection of disease symptoms from clinical notes [3]. These notes contain free text information from emergency department admission and discharge, details related to patient allergy, medication, previous visits had ', 'Spark NLP: Natural Language Understanding at Scale Veysel Kocaman, David Talby John Snow Labs Inc. 16192 Coastal Highway Lewes, DE , USA 19958 veysel, david@johnsnowlabs.com Abstract Spark NLP is a Natural Language Processing (NLP) library built on top of Apache Spark ML. It provides simple, performant & accurate NLP annotations for machine learning pipelines that can scale easily in a distributed environment. Spark NLP comes with 1100+ pretrained pipelines and models in more than 192+ languages. It supports nearly all the NLP tasks and modules that can be used seam- lessly in a cluster. Downloaded more than 2.7 million times and experiencing 9x growth since January 2020, Spark NLP is used by 54% of healthcare organizations as the world’s most widely used NLP library in the enterprise. Keywords: spark, natural language processing, deep learning, tensorﬂow, cluster 1. Spark NLP Library Natural language processing (NLP) is a key component in many data ']], 'title': [['placeholder_title', 'placeholder_title', 'placeholder_title', 'placeholder_title', 'placeholder_title']]\nSpark NLP comes with 1100+ pretrained pipelines and models in more than 192+ languages. It supports nearly all the NLP tasks and modules that can be used seam-lessly in a cluster.\n","output_type":"stream"}]},{"cell_type":"code","source":"def preprocess_function(examples):\n    inputs = [\n        f\"question: {q} context: {c}\" for q, c in zip(examples['question'], examples['context'])\n    ]\n    targets = examples['answer']\n    model_inputs = tokenizer(inputs, max_length=1500, truncation=True, padding='max_length')\n\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(targets, max_length=128, truncation=True, padding='max_length')\n\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n\ntokenized_dataset = train_dataset.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:13:57.444991Z","iopub.execute_input":"2024-10-23T11:13:57.445873Z","iopub.status.idle":"2024-10-23T11:14:01.368798Z","shell.execute_reply.started":"2024-10-23T11:13:57.445831Z","shell.execute_reply":"2024-10-23T11:14:01.367683Z"},"trusted":true},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/440 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42b588d38c4149fcb0011e0e63f03077"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4117: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenized_dataset","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:14:04.499932Z","iopub.execute_input":"2024-10-23T11:14:04.500363Z","iopub.status.idle":"2024-10-23T11:14:04.506970Z","shell.execute_reply.started":"2024-10-23T11:14:04.500321Z","shell.execute_reply":"2024-10-23T11:14:04.505891Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['id', 'type', 'question', 'context', 'answer', 'cot_answer', 'input_ids', 'attention_mask', 'labels'],\n    num_rows: 440\n})"},"metadata":{}}]},{"cell_type":"code","source":"import torch\n\ntorch.cuda.empty_cache()\n","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:15:19.006039Z","iopub.execute_input":"2024-10-23T11:15:19.007167Z","iopub.status.idle":"2024-10-23T11:15:19.012213Z","shell.execute_reply.started":"2024-10-23T11:15:19.007116Z","shell.execute_reply":"2024-10-23T11:15:19.011264Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments\n\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    per_device_train_batch_size=2,\n    num_train_epochs=3,\n    learning_rate=5e-5,\n    eval_strategy=\"no\",  # Disable evaluation\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset,\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:16:00.173855Z","iopub.execute_input":"2024-10-23T11:16:00.174606Z","iopub.status.idle":"2024-10-23T11:23:30.757154Z","shell.execute_reply.started":"2024-10-23T11:16:00.174568Z","shell.execute_reply":"2024-10-23T11:23:30.756253Z"},"trusted":true},"execution_count":40,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='660' max='660' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [660/660 07:28, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.501600</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=660, training_loss=0.4194406336004084, metrics={'train_runtime': 449.9302, 'train_samples_per_second': 2.934, 'train_steps_per_second': 1.467, 'total_flos': 2354954342400000.0, 'train_loss': 0.4194406336004084, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.save_model('./fine_tuned_t5_model')\ntokenizer.save_pretrained('./fine_tuned_t5_model')","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:23:51.268360Z","iopub.execute_input":"2024-10-23T11:23:51.268777Z","iopub.status.idle":"2024-10-23T11:23:53.041389Z","shell.execute_reply.started":"2024-10-23T11:23:51.268738Z","shell.execute_reply":"2024-10-23T11:23:53.040437Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"('./fine_tuned_t5_model/tokenizer_config.json',\n './fine_tuned_t5_model/special_tokens_map.json',\n './fine_tuned_t5_model/spiece.model',\n './fine_tuned_t5_model/added_tokens.json')"},"metadata":{}}]},{"cell_type":"markdown","source":"Note that enabling LoRA reduces the number of trainable parameters significantly (from 2.5 billion to 1.3 million).","metadata":{"id":"hQQ47kcdpbZ9","papermill":{"duration":0.011797,"end_time":"2024-02-21T09:39:33.903795","exception":false,"start_time":"2024-02-21T09:39:33.891998","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Load Fine-tuned model\n","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\nmodel_path = '/kaggle/working/fine_tuned_t5_model'\n\ntokenizer = AutoTokenizer.from_pretrained(model_path)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_path)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:24:21.970577Z","iopub.execute_input":"2024-10-23T11:24:21.971561Z","iopub.status.idle":"2024-10-23T11:24:22.780381Z","shell.execute_reply.started":"2024-10-23T11:24:21.971517Z","shell.execute_reply":"2024-10-23T11:24:22.779586Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stderr","text":"You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n","output_type":"stream"}]},{"cell_type":"code","source":"device = 0 if torch.cuda.is_available() else -1\ntext2text_generator = pipeline('text2text-generation', model=model, tokenizer=tokenizer, device = device)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:24:26.353887Z","iopub.execute_input":"2024-10-23T11:24:26.354300Z","iopub.status.idle":"2024-10-23T11:24:26.692271Z","shell.execute_reply.started":"2024-10-23T11:24:26.354260Z","shell.execute_reply":"2024-10-23T11:24:26.691493Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"## Inference after fine-tuning\nAfter fine-tuning, responses follow the instruction provided in the prompt.","metadata":{"id":"4yd-1cNw1dTn","papermill":{"duration":0.092253,"end_time":"2024-02-21T09:52:07.553072","exception":false,"start_time":"2024-02-21T09:52:07.460819","status":"completed"},"tags":[]}},{"cell_type":"code","source":"print(inference_data[0])\nanswer = text2text_generator(inference_data[0])\nprint(answer)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:24:29.707964Z","iopub.execute_input":"2024-10-23T11:24:29.708356Z","iopub.status.idle":"2024-10-23T11:24:30.234653Z","shell.execute_reply.started":"2024-10-23T11:24:29.708319Z","shell.execute_reply":"2024-10-23T11:24:30.233589Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (1324 > 512). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"name":"stdout","text":"Instruction:\nWhat is the main topic of the text?\n\nContext:\n\ntopic comprised of four broad topics: 1.Introduction: An overview of NLP and its use- fulness in Economics; Python fundamentals 2.Python & textual data, which focused on data collection, text extraction, pre-processing and text representation 3.NLP methods for economics, covering ex- ploratory corpus analysis, text classiﬁcation, topic modeling, and giving an overview of others such as information extraction and text summarization 4.NLP in Economics - research paper readings and discussion The students had to do 3 assignments covering the ﬁrst three topics which involved writing small python programs to use existing tools and write an analysis of how they work for their domain data. They also did a group presentation picking a paper that used NLP methods to address research ques- tions in economics, chosen most often from their own disciplinary journals, instead of NLP confer- ences. Students also had to submit a term paper which involved creation of a problem \nsections, we discuss how we approached selecting papers to serve as the base of student replications, and how we scaffold the skills necessary to complete it. Types of papers and why In choosing papers, we focused on the core themes of the course andlooked for papers that were (often) short, con- tained existing code, exposed a key methodology, and would facilitate good discussions. We settled on 5 themes: Basic Methodology, Interpretability, Experimental Design, Cross-Linguistic or Multi- linguality, What’s in the Data. Example papers are provided in Table 2. The Basic Methodology theme serves a particular function in scaffolding the midterm project, which we return to below. For the others, we wanted to highlight different approaches for evaluating models (Interpretability), how care- fully created experiments can expose flaws in sci- entific reasoning (Experimental Design), how we should think broadly about language (cf. the “Ben- der Rule”, Bender 2019; Multilinguality), and how \nwith keyword and key phrase extraction ap- proaches. The next topics focused on text classiﬁ- cation and topic modeling - both of which are the most commonly used methods with textual data across disciplines. The ﬁnal topic for the course discussed various means of visualizing textual data. Evaluation: The course included assignments that followed the topic structure, and required stu- dents to write small R programs to extract text patterns, scrape data from different forms of doc- uments (e.g., webpages, twitter), extracting key- words, ngrams etc., following step by step process making alterations to pre-written code for training a text classiﬁer and a topic model, and building ba- sic visualizations of textual data (e.g., word clouds, dispersion plots etc). All assignments relied on learning to use existing R libraries instead of fo- cusing on building everything from scratch. The students did a group presentation which involved visualizing textual data. The \nthis category.Semantic Parsing, Sentiment Analysis, Text Annotation, Se- mantic Annotation, Topic Modelling, SRL, Summarization, LDA, LSI, Semantic Patterns, Case Grammar, Semantic Frames, Knowledge Graph, TER, Homonym Detection, Syn- onymy Detection Discourse This level focuses on the properties of the text as a whole that convey meaning by making connections between component sentences. Only three techniques belong to this category.Coreference Resolution, Anaphora Resolution, Generation Rules [12] R. J. Abbott, “Program design by informal english descriptions,” Communications of the ACM , vol. 26, no. 11, pp. 882–894, 1983. [13] D. M. Berry, N. Yavne, and M. Yavne, “Application of program design language tools to abbott’s method of program design by informal natural language descriptions,” Journal of Systems and Software , vol. 7, no. 3, pp. 221–247, 1987. [Online]. Available: https://www.sciencedirect.com/science/article/pii/0164121287900446 [14] G. Booch, R. A. Maksimchuk, M. W. Engle, B. J. Young, J. Connallen, and K. A. Houston, “Object-oriented analysis and design \nnomenonnuclear, weapon, fusion, neutron, reactor, plutonium, radioactive, demand, debris, skin 53 Air Shock Phenom- enawave, angle, supersonic, mach, reflected, sonic, subsonic, reproduced, overtakes, coworkers 162 Propellant Deflagra- tionpropellant, temperature, graphite, explosive, material, high, octahy- dro1357tetranitro1357tetrazocine, hexahydro135trinitro135triazine, boron, pres- sure 29 None one, individual, best, interval, shift, constituent, implies, rolling, overlap, shift- ing 45 None series, strength, failed, transmitted, material, hypothesis, picture, tensile, whilst, reveals Table 1: Selected LDA Topics and associated ten highest probability keywords. The topic number is automatically generated by the model training software and has no physical interpretation. The top ten topics are highly interpetable, however the final two topics keywords lists (separated by the horizontal black line) lack coherency and cannot be readily assigned to a specific energetic subdiscipline. Examination of the first ten topics presented in Table 1 reveals a clear pattern of keyword grouping in a manner immediately recognizable to those with energetics knowledge. \n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1220: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"[{'generated_text': 'The text comprises four broad topics: Introduction to NLP and its use- fulness in Economics'}]\n","output_type":"stream"}]},{"cell_type":"code","source":"predictions = []\nreferences = []\n\nfor i in range(len(inference_data)):\n    print(\"inference example: \", i)\n    answer = text2text_generator(inference_data[i])\n    predictions.append(answer[0]['generated_text'])\n    \n    target_answer = test_data['answer'].iloc[i]\n    references.append(target_answer)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:24:49.012766Z","iopub.execute_input":"2024-10-23T11:24:49.013181Z","iopub.status.idle":"2024-10-23T11:27:51.129692Z","shell.execute_reply.started":"2024-10-23T11:24:49.013133Z","shell.execute_reply":"2024-10-23T11:27:51.128867Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"inference example:  0\ninference example:  1\ninference example:  2\ninference example:  3\ninference example:  4\ninference example:  5\ninference example:  6\ninference example:  7\ninference example:  8\n","output_type":"stream"},{"name":"stderr","text":"You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","output_type":"stream"},{"name":"stdout","text":"inference example:  9\ninference example:  10\ninference example:  11\ninference example:  12\ninference example:  13\ninference example:  14\ninference example:  15\ninference example:  16\ninference example:  17\ninference example:  18\ninference example:  19\ninference example:  20\ninference example:  21\ninference example:  22\ninference example:  23\ninference example:  24\ninference example:  25\ninference example:  26\ninference example:  27\ninference example:  28\ninference example:  29\ninference example:  30\ninference example:  31\ninference example:  32\ninference example:  33\ninference example:  34\ninference example:  35\ninference example:  36\ninference example:  37\ninference example:  38\ninference example:  39\ninference example:  40\ninference example:  41\ninference example:  42\ninference example:  43\ninference example:  44\ninference example:  45\ninference example:  46\ninference example:  47\ninference example:  48\ninference example:  49\ninference example:  50\ninference example:  51\ninference example:  52\ninference example:  53\ninference example:  54\ninference example:  55\ninference example:  56\ninference example:  57\ninference example:  58\ninference example:  59\ninference example:  60\ninference example:  61\ninference example:  62\ninference example:  63\ninference example:  64\ninference example:  65\ninference example:  66\ninference example:  67\ninference example:  68\ninference example:  69\ninference example:  70\ninference example:  71\ninference example:  72\ninference example:  73\ninference example:  74\ninference example:  75\ninference example:  76\ninference example:  77\ninference example:  78\ninference example:  79\ninference example:  80\ninference example:  81\ninference example:  82\ninference example:  83\ninference example:  84\ninference example:  85\ninference example:  86\ninference example:  87\ninference example:  88\ninference example:  89\ninference example:  90\ninference example:  91\ninference example:  92\ninference example:  93\ninference example:  94\ninference example:  95\ninference example:  96\ninference example:  97\ninference example:  98\ninference example:  99\ninference example:  100\ninference example:  101\ninference example:  102\ninference example:  103\ninference example:  104\ninference example:  105\ninference example:  106\ninference example:  107\ninference example:  108\ninference example:  109\ninference example:  110\ninference example:  111\ninference example:  112\ninference example:  113\ninference example:  114\ninference example:  115\ninference example:  116\ninference example:  117\ninference example:  118\ninference example:  119\ninference example:  120\ninference example:  121\ninference example:  122\ninference example:  123\ninference example:  124\ninference example:  125\ninference example:  126\ninference example:  127\ninference example:  128\ninference example:  129\ninference example:  130\ninference example:  131\ninference example:  132\ninference example:  133\ninference example:  134\ninference example:  135\ninference example:  136\ninference example:  137\ninference example:  138\ninference example:  139\ninference example:  140\ninference example:  141\ninference example:  142\ninference example:  143\ninference example:  144\ninference example:  145\ninference example:  146\ninference example:  147\ninference example:  148\ninference example:  149\ninference example:  150\ninference example:  151\ninference example:  152\ninference example:  153\ninference example:  154\ninference example:  155\ninference example:  156\ninference example:  157\ninference example:  158\ninference example:  159\ninference example:  160\ninference example:  161\ninference example:  162\ninference example:  163\ninference example:  164\ninference example:  165\ninference example:  166\ninference example:  167\ninference example:  168\ninference example:  169\ninference example:  170\ninference example:  171\ninference example:  172\ninference example:  173\ninference example:  174\ninference example:  175\ninference example:  176\ninference example:  177\ninference example:  178\ninference example:  179\ninference example:  180\ninference example:  181\ninference example:  182\ninference example:  183\ninference example:  184\ninference example:  185\ninference example:  186\ninference example:  187\ninference example:  188\ninference example:  189\ninference example:  190\ninference example:  191\ninference example:  192\ninference example:  193\ninference example:  194\ninference example:  195\ninference example:  196\ninference example:  197\ninference example:  198\ninference example:  199\ninference example:  200\ninference example:  201\ninference example:  202\ninference example:  203\ninference example:  204\ninference example:  205\ninference example:  206\ninference example:  207\ninference example:  208\ninference example:  209\ninference example:  210\ninference example:  211\ninference example:  212\ninference example:  213\ninference example:  214\ninference example:  215\ninference example:  216\ninference example:  217\ninference example:  218\ninference example:  219\ninference example:  220\ninference example:  221\ninference example:  222\ninference example:  223\ninference example:  224\ninference example:  225\ninference example:  226\ninference example:  227\ninference example:  228\ninference example:  229\ninference example:  230\ninference example:  231\ninference example:  232\ninference example:  233\ninference example:  234\ninference example:  235\ninference example:  236\ninference example:  237\ninference example:  238\ninference example:  239\ninference example:  240\ninference example:  241\ninference example:  242\ninference example:  243\ninference example:  244\ninference example:  245\ninference example:  246\ninference example:  247\ninference example:  248\ninference example:  249\ninference example:  250\ninference example:  251\ninference example:  252\ninference example:  253\ninference example:  254\ninference example:  255\ninference example:  256\ninference example:  257\ninference example:  258\ninference example:  259\ninference example:  260\ninference example:  261\ninference example:  262\ninference example:  263\ninference example:  264\ninference example:  265\ninference example:  266\ninference example:  267\ninference example:  268\ninference example:  269\ninference example:  270\ninference example:  271\ninference example:  272\ninference example:  273\ninference example:  274\ninference example:  275\ninference example:  276\ninference example:  277\ninference example:  278\ninference example:  279\ninference example:  280\ninference example:  281\ninference example:  282\ninference example:  283\ninference example:  284\ninference example:  285\ninference example:  286\ninference example:  287\ninference example:  288\ninference example:  289\ninference example:  290\ninference example:  291\ninference example:  292\ninference example:  293\ninference example:  294\ninference example:  295\ninference example:  296\ninference example:  297\ninference example:  298\ninference example:  299\ninference example:  300\ninference example:  301\ninference example:  302\ninference example:  303\ninference example:  304\ninference example:  305\ninference example:  306\ninference example:  307\ninference example:  308\ninference example:  309\ninference example:  310\ninference example:  311\ninference example:  312\ninference example:  313\ninference example:  314\ninference example:  315\ninference example:  316\ninference example:  317\ninference example:  318\ninference example:  319\ninference example:  320\ninference example:  321\ninference example:  322\ninference example:  323\ninference example:  324\ninference example:  325\ninference example:  326\ninference example:  327\ninference example:  328\ninference example:  329\ninference example:  330\ninference example:  331\ninference example:  332\ninference example:  333\ninference example:  334\ninference example:  335\ninference example:  336\ninference example:  337\ninference example:  338\ninference example:  339\ninference example:  340\ninference example:  341\ninference example:  342\ninference example:  343\ninference example:  344\ninference example:  345\ninference example:  346\ninference example:  347\ninference example:  348\ninference example:  349\ninference example:  350\ninference example:  351\ninference example:  352\ninference example:  353\ninference example:  354\ninference example:  355\ninference example:  356\ninference example:  357\ninference example:  358\ninference example:  359\ninference example:  360\ninference example:  361\ninference example:  362\ninference example:  363\ninference example:  364\ninference example:  365\ninference example:  366\ninference example:  367\ninference example:  368\ninference example:  369\ninference example:  370\ninference example:  371\ninference example:  372\ninference example:  373\ninference example:  374\ninference example:  375\ninference example:  376\ninference example:  377\ninference example:  378\ninference example:  379\ninference example:  380\ninference example:  381\ninference example:  382\ninference example:  383\ninference example:  384\ninference example:  385\ninference example:  386\ninference example:  387\ninference example:  388\ninference example:  389\ninference example:  390\ninference example:  391\ninference example:  392\ninference example:  393\ninference example:  394\ninference example:  395\ninference example:  396\ninference example:  397\ninference example:  398\ninference example:  399\ninference example:  400\ninference example:  401\ninference example:  402\ninference example:  403\ninference example:  404\ninference example:  405\ninference example:  406\ninference example:  407\ninference example:  408\ninference example:  409\ninference example:  410\ninference example:  411\ninference example:  412\ninference example:  413\ninference example:  414\ninference example:  415\ninference example:  416\ninference example:  417\ninference example:  418\ninference example:  419\ninference example:  420\ninference example:  421\ninference example:  422\ninference example:  423\ninference example:  424\ninference example:  425\ninference example:  426\ninference example:  427\ninference example:  428\ninference example:  429\ninference example:  430\ninference example:  431\ninference example:  432\ninference example:  433\ninference example:  434\ninference example:  435\ninference example:  436\ninference example:  437\ninference example:  438\ninference example:  439\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(predictions))\nprint(predictions[10])\nprint(references[10])","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:30:30.235879Z","iopub.execute_input":"2024-10-23T11:30:30.236492Z","iopub.status.idle":"2024-10-23T11:30:30.243494Z","shell.execute_reply.started":"2024-10-23T11:30:30.236453Z","shell.execute_reply":"2024-10-23T11:30:30.242655Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"440\nThe text is intended to provide a framework for understanding the structure of sentences and generating meaningful\nTo describe the process of surveying papers retrieved from databases\n","output_type":"stream"}]},{"cell_type":"code","source":"results = bertscore.compute(predictions=predictions, references=references, model_type=\"distilbert-base-uncased\")\nscore = sum(results['f1']) / len(results['f1'])\nprint(score)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:29:43.702582Z","iopub.execute_input":"2024-10-23T11:29:43.703005Z","iopub.status.idle":"2024-10-23T11:29:47.295763Z","shell.execute_reply.started":"2024-10-23T11:29:43.702963Z","shell.execute_reply":"2024-10-23T11:29:47.294595Z"},"trusted":true},"execution_count":52,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5812f88f74e4424ad6232514aa30c0a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14bdec8602554335bf2fec1212fab7d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd390d9346084001991ac55b8a0f3fba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff61147c29c644438e36352e084c5f2f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2bd7462f10da41f6bbed7f9802961414"}},"metadata":{}},{"name":"stdout","text":"0.7559248475865884\n","output_type":"stream"},{"name":"stderr","text":"Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\nWarning: Empty candidate sentence detected; setting raw BERTscores to 0.\nWarning: Empty candidate sentence detected; setting raw BERTscores to 0.\nWarning: Empty candidate sentence detected; setting raw BERTscores to 0.\nWarning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","output_type":"stream"}]}]}